---
title: "human_analyses"
author: "Zachary Houghton"
date: "2025-12-03"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(brms)
library(jsonlite)
library(patchwork)
```

# Load Data

```{r}
corpus = read_csv('../Data/nonce_and_attested_binoms.csv')

human_data = read_csv('data.csv')

human_data = human_data %>%
  filter(!is.na(mouse.clicked_name)) %>%
  mutate(parsed = map(mouse.clicked_name, fromJSON)) %>%
  # Remove NULL / NA elements from each parsed list
  mutate(parsed_clean = map(parsed, ~ discard(.x, is.null))) %>%
  # Also drop NA strings if they appear
  mutate(parsed_clean = map(parsed_clean, ~ discard(.x, ~ is.na(.x)))) %>%
  # Keep only rows where at least 2 elements remain
  filter(lengths(parsed_clean) >= 2) %>%
  # Extract second-to-last element
  mutate(raw_resp = map_chr(parsed_clean, ~ .x[length(.x) - 1])) %>%
  select(-parsed) %>%
  mutate(resp = case_when(
    raw_resp == 'text_10' ~ 'alpha',
    raw_resp == 'text_11' ~ 'nonalpha'
  )) %>%
  select(`SESSION_ID`, mouse.clicked_name, raw_resp, resp, Word1, Word2) %>%
  rename('participant' = `SESSION_ID`) %>%
  left_join(corpus)
  

human_data_plot = human_data %>%
  filter(!is.na(resp))

ggplot(human_data_plot, aes(x = GenPref, y = RelFreq, color = resp)) +
  geom_point(alpha = 0.6) +
  theme_minimal()

ggplot(human_data_plot, aes(GenPref, RelFreq, color = resp)) +
  geom_point(alpha = 0.5) +
  stat_smooth(method = "glm", method.args = list(family = binomial),
              se = FALSE, color = "black") +
  theme_minimal()


human_data_plot = human_data_plot %>%
  mutate(
    OverallFreq_log = log10(OverallFreq + 1),
    OverallFreq_bin = ntile(OverallFreq_log, 3)  # low/mid/high frequency
  )

p1 = library(dplyr)
library(ggplot2)

human_data_plot <- human_data_plot %>%
  mutate(
    OverallFreq_log = log10(OverallFreq + 1),
    OverallFreq_bin = ntile(OverallFreq_log, 3),    # low/mid/high
    GenPref_bin = cut(GenPref, breaks = 20)         # 20 bins from 0–1
  )

df_gen <- human_data_plot %>%
  group_by(OverallFreq_bin, GenPref_bin) %>%
  summarize(
    GenPref_mid = mean(GenPref),
    prop_alpha = mean(resp == "alpha"),
    n = n(),
    .groups = "drop"
  )

p1 = ggplot(human_data_plot,
       aes(
         x = GenPref,
         y = log10(OverallFreq + 1),
         z = as.numeric(resp == "alpha")
       )) +
  stat_summary_hex(
    fun = mean,
    bins = 40
  ) +
  scale_fill_viridis_c(option = "magma", name = "Pr(alpha)") +
  theme_minimal() +
  labs(
    x = "GenPref",
    y = "log10(OverallFreq + 1)",
    #title = "Raw probability of alpha across GenPref × OverallFreq"
  )


human_data_plot <- human_data_plot %>%
  mutate(RelFreq_bin = cut(RelFreq, breaks = 20))

df_rel <- human_data_plot %>%
  group_by(OverallFreq_bin, RelFreq_bin) %>%
  summarize(
    RelFreq_mid = mean(RelFreq),
    prop_alpha = mean(resp == "alpha"),
    n = n(),
    .groups = "drop"
  )

p2 = ggplot(human_data_plot,
       aes(
         x = RelFreq,
         y = log10(OverallFreq + 1),
         z = as.numeric(resp == "alpha")
       )) +
  stat_summary_hex(
    fun = mean,
    bins = 40
  ) +
  scale_fill_viridis_c(option = "magma", name = "Pr(alpha)") +
  theme_minimal() +
  labs(
    x = "RelFreq",
    y = "log10(OverallFreq + 1)",
    #title = "Raw probability of alpha across RelFreq × OverallFreq"
  )



p1 + p2

```



```{r}
human_data = human_data %>%
  mutate(GenPref = GenPref - 0.5,
         RelFreq = RelFreq - 0.5,
         LogCenteredOverallFreq = scale(log(OverallFreq))) #logged and centered 

prior_probs = c(
  prior(student_t(3, 0, 0.1), class = 'Intercept'),
  prior(student_t(3, 0, 0.05), class = 'sd'),
  prior(student_t(3, 0, 0.05), class = 'b')
)

human_data$participant = factor(human_data$participant)

human_data = human_data %>%
  mutate(Item = dense_rank(Alpha))

human_data$Item = factor(human_data$Item)

human_data = human_data %>%
  mutate(resp = case_when(
    resp == 'alpha' ~ 1,
    resp == 'nonalpha' ~ 0
  ))

human_data$resp = factor(human_data$resp)

m1 = brm(
  resp ~ GenPref + RelFreq + LogCenteredOverallFreq + GenPref:LogCenteredOverallFreq + RelFreq:LogCenteredOverallFreq + (GenPref + RelFreq + LogCenteredOverallFreq + GenPref:LogCenteredOverallFreq + RelFreq:LogCenteredOverallFreq | participant) + (1 | Item),
  data = human_data,
  family = bernoulli(link = "logit"),
  chains = 4,   
  cores = 4,
  iter = 20000,  
  warmup = 10000,
  prior = prior_probs,
  control = list(adapt_delta=0.99, max_treedepth = 20),
  file = '../Data/human_data_model_results'
)

fixef(m1)
```

## Nonce and attested binoms human data

```{r}
nonce_data = read.csv('human-prefs-nonce.csv') %>%
  dplyr::select(-Q10, -`Q9_2_TEXT`)

binoms = read_csv('../Data/nonce_binoms.csv')

nonce_data = nonce_data[4:nrow(nonce_data),]

nonce_data = nonce_data %>%
  pivot_longer(!ResponseId, names_to = 'Question', values_to = 'Answer') %>%
  filter(grepl("^Q", Question)) %>%
  filter(grepl('and', Answer))

nonce_data = nonce_data %>%
  mutate(
    # Split binomial into two words
    wordA = str_trim(word(Answer, 1)),
    wordB = str_trim(word(Answer, -1)),
    
    # Alphabetically order the two words
    Word1 = pmin(wordA, wordB),
    Word2 = pmax(wordA, wordB)
  ) %>%
  dplyr::select(-wordA, -wordB) %>%
  left_join(binoms)

nonce_data = nonce_data %>%
  mutate(alpha_answer = case_when(
    Answer == Alpha ~ 1,
    Answer == Nonalpha ~ 0
  ))

nonce_data = nonce_data %>%
  mutate(participant = ResponseId, resp = Answer, RelFreq = 0, Attested = 1) %>%
  mutate(raw_resp = resp, resp = ifelse(raw_resp == Alpha, 'alpha', 'nonalpha')) %>%
  select(participant, resp, Word1, Word2, Alpha, Nonalpha, OverallFreq, Word1_freq, Word2_freq, Form, Percept, Culture, Power, Intense, Icon, Freq, Len, Lapse, "*BStress", RelFreq, GenPref, Attested)

human_data = human_data %>%
  select(participant, resp, Word1, Word2, Alpha, Nonalpha, OverallFreq, Word1_freq, Word2_freq, Form, Percept, Culture, Power, Intense, Icon, Freq, Len, Lapse, "*BStress", RelFreq, GenPref, Attested)


all_human_data = nonce_data %>%
  full_join(human_data)

#write_csv(all_human_data, 'all_human_data.csv')

```

Generate predicted ordering pref for our finetuning corpus:

```{r}
finetuning_corpus = read_csv("../Data/fintetuning-binoms-with-constraints-coded.csv") %>%
  mutate(LogCenteredOverallFreq = as.numeric(scale(OverallFreq))) %>%
  mutate(
    GenPref = GenPref - 0.5,
    RelFreq = RelFreq - 0.5
  ) %>%
  filter(WordA != WordB)


#predict human preference with finetuning corpus

pred_summ = fitted(
  m1,
  newdata    = finetuning_corpus,
  re_formula = NA,   # again, population-level
  summary    = TRUE  # default
)

# This gives:
#   Estimate   Est.Error     Q2.5    Q97.5
# on the response scale (probabilities, because family = bernoulli)
finetuning_corpus_with_model_preds = cbind(finetuning_corpus, pred_summ) %>%
  mutate(item = row_number())

finetuning_corpus_with_model_preds = finetuning_corpus_with_model_preds %>%
  uncount(weights = 10, .remove = F) %>%
  group_by(item) %>%
  mutate(predicted_resp_value = rbinom(n(), size = 1, prob = Estimate)) %>%
  ungroup() 


finetuning_corpus_with_model_preds = finetuning_corpus_with_model_preds %>%
  mutate(predicted_resp = case_when(
    predicted_resp_value == 1 ~ paste0(WordA, ' and ', WordB),
    predicted_resp_value == 0 ~ paste0(WordB, ' and ', WordA)
  ))

#write_csv(finetuning_corpus_with_model_preds, '../Data/fintetuning-corpus-with-model-preds.csv')
```

```{r}
finetuning_corpus_with_model_preds_rel_freq = finetuning_corpus_with_model_preds %>%
  select(-predicted_resp_value, -predicted_resp) %>%
  group_by(item) %>%
  mutate(RelFreqProb = RelFreq + 0.5) %>%
  mutate(relfreq_resp_value = rbinom(n(), size = 1, prob = RelFreqProb)) %>%
  ungroup() 


finetuning_corpus_with_model_preds_rel_freq = finetuning_corpus_with_model_preds_rel_freq %>%
  mutate(relfreq_resp = case_when(
    relfreq_resp_value == 1 ~ paste0(WordA, ' and ', WordB),
    relfreq_resp_value == 0 ~ paste0(WordB, ' and ', WordA)
  ))


#write_csv(finetuning_corpus_with_model_preds_rel_freq, '../Data/fintetuning-corpus-with-model-preds-relfreq.csv')
```


