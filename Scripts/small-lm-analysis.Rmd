---
title: "small-lm-analysis"
author: "Zachary Houghton"
date: "2025-07-17"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(brms)
```

# Genpref and Individual Constraint Analyses

## Baseline model

```{r}
options(contrasts = c("contr.sum","contr.sum"))

corpus = read_csv('../Data/nonce_and_attested_binoms.csv')

baseline_model_data = read_csv('../Data/SMALL_MODEL_BINOMIAL_PREFERENCES.csv') %>%
  mutate(log_odds = preference) %>%
  separate(binom, c('Word1', 'and', 'Word2'), remove = F, sep = ' ') %>%
  select(-and) %>%
  #mutate(across(2:3, tolower)) %>%
  left_join(corpus) %>%
  mutate(checkpoint = 'main') %>%
  mutate(y_vals = 0.02191943 + 0.23925834*Form +  0.24889543*Percept +  0.41836997*Culture +   0.25967334*Power +  0.01867604*Intense +  1.30365980*Icon +   0.08553552*Freq +  0.15241566*Len - 0.19381657*Lapse +  0.36019221*`*BStress`) %>%
  mutate(GenPref = 1/(1+exp(-1*y_vals))) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5) %>%
  ungroup()


small_attested = read_csv('../Data/SMALL_MODEL_BINOMIAL_PREFERENCES.csv') %>%
  mutate(log_odds = preference) %>%
  separate(binom, c('Word1', 'and', 'Word2'), remove = F, sep = ' ') %>%
  select(-and) %>%
  #mutate(across(2:3, tolower)) %>%
  left_join(corpus) %>%
  mutate(checkpoint = 'main') %>%
  mutate(y_vals = 0.02191943 + 0.23925834*Form +  0.24889543*Percept +  0.41836997*Culture +   0.25967334*Power +  0.01867604*Intense +  1.30365980*Icon +   0.08553552*Freq +  0.15241566*Len - 0.19381657*Lapse +  0.36019221*`*BStress`) %>%
  mutate(GenPref = 1/(1+exp(-1*y_vals))) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5) %>%
  ungroup() %>%
  filter(Attested == 1) %>%
  mutate(CenteredOverallFreq = scale(log(OverallFreq))) 


small_novel = read_csv('../Data/SMALL_MODEL_BINOMIAL_PREFERENCES.csv') %>%
  mutate(log_odds = preference) %>%
  separate(binom, c('Word1', 'and', 'Word2'), remove = F, sep = ' ') %>%
  select(-and) %>%
  #mutate(across(2:3, tolower)) %>%
  left_join(corpus) %>%
  mutate(checkpoint = 'main') %>%
  mutate(y_vals = 0.02191943 + 0.23925834*Form +  0.24889543*Percept +  0.41836997*Culture +   0.25967334*Power +  0.01867604*Intense +  1.30365980*Icon +   0.08553552*Freq +  0.15241566*Len - 0.19381657*Lapse +  0.36019221*`*BStress`) %>%
  mutate(GenPref = 1/(1+exp(-1*y_vals))) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  filter(Attested == 0)

small_attested$prompt = factor(small_attested$prompt)
small_novel$prompt = factor(small_novel$prompt)

small_novel = small_novel %>%
  rename(no_final_stress = "*BStress")

small_attested = small_attested %>%
  rename(no_final_stress = "*BStress")

model_small_attested_genpref = brm(log_odds ~ GenPref + RelFreq + CenteredOverallFreq + GenPref:CenteredOverallFreq + RelFreq:CenteredOverallFreq + (GenPref | prompt) + (1 | Alpha),
                       data = small_attested,
                       #prior = prior_probs,
                       iter = 10000,
                       warmup = 5000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/model_small_attested_genpref'
                      )


model_small_novel_genpref = brm(log_odds ~ GenPref + (GenPref | prompt) + (1 | Alpha),
                       data = small_novel,
                       #prior = prior_probs,
                       iter = 10000,
                       warmup = 5000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       #control = list(max_treedepth = 20),
                       file = '../Data/model_small_novel_genpref'
                      )


### Vif then backward model selection
# 
# model_small_novel_individual_constraints = brm(log_odds ~ Culture + Power + Freq + Len + no_final_stress + Intense + Percept + Lapse + (Culture + Power + Freq + Len + no_final_stress + Intense + Percept + Lapse | prompt) + ( 1 | Alpha),
#                        data = small_novel,
#                        #prior = prior_probs,
#                        iter = 10000,
#                        warmup = 5000,
#                        chains = 4,
#                        cores = 4,
#                        #control = list(adapt_delta=0.99, max_treedepth = 15),
#                        #control = list(max_treedepth = 20),
#                        file = '../Data/model_small_novel_individual_constraints'
#                       )
 

fixef(model_small_attested_genpref)
fixef(model_small_novel_genpref)
#fixef(model_small_novel_individual_constraints)
#car::vif(model_small_novel_individual_constraints)


## Now we do backward model selection? For this project we might actually want to *not* do backward model selection, because constraints that are centered around zero may change after finetuning.


```
## Finetuned on Genpref

```{r}
options(contrasts = c("contr.sum","contr.sum"))

corpus = read_csv('../Data/nonce_and_attested_binoms.csv')

model_data_finetuned_genpref = read_csv('../Data/FINETUNED_GENPREF_MODEL_BINOMIAL_PREFERENCES.csv') %>%
  mutate(log_odds = preference) %>%
  separate(binom, c('Word1', 'and', 'Word2'), remove = F, sep = ' ') %>%
  select(-and) %>%
  #mutate(across(2:3, tolower)) %>%
  left_join(corpus) %>%
  mutate(checkpoint = 'main') %>%
  mutate(y_vals = 0.02191943 + 0.23925834*Form +  0.24889543*Percept +  0.41836997*Culture +   0.25967334*Power +  0.01867604*Intense +  1.30365980*Icon +   0.08553552*Freq +  0.15241566*Len - 0.19381657*Lapse +  0.36019221*`*BStress`) %>%
  mutate(GenPref = 1/(1+exp(-1*y_vals))) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5) %>%
  ungroup() %>%
  filter(model == "qing-yao/genfreq-finetuned-ep10_seed-42_1e-4")


small_attested_genpref = model_data_finetuned_genpref %>%
  filter(Attested == 1) %>%
  mutate(CenteredOverallFreq = scale(log(OverallFreq))) 


small_novel_genpref = model_data_finetuned_genpref %>%
  filter(Attested == 0)

small_attested_genpref$prompt = factor(small_attested_genpref$prompt)
small_novel_genpref$prompt = factor(small_novel_genpref$prompt)

small_novel_genpref = small_novel_genpref %>%
  rename(no_final_stress = "*BStress")

small_attested_genpref = small_attested_genpref %>%
  rename(no_final_stress = "*BStress")



model_small_attested_genpref_finetuned = brm(log_odds ~ (GenPref + RelFreq + CenteredOverallFreq + GenPref:CenteredOverallFreq + RelFreq:CenteredOverallFreq) + (GenPref | prompt) + (1 | Alpha),
                       data = small_attested_genpref,
                       #prior = prior_probs,
                       iter = 10000,
                       warmup = 5000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/model_small_attested_genpref_finetuned'
                      )


model_small_novel_genpref_finetuned = brm(log_odds ~ GenPref + (GenPref | prompt) + (1 | Alpha),
                       data = small_novel_genpref,
                       #prior = prior_probs,
                       iter = 10000,
                       warmup = 5000,
                       chains = 4,
                       
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       #control = list(max_treedepth = 20),
                       file = '../Data/model_small_novel_genpref_finetuned'
                      )


### Vif then backward model selection

# model_small_novel_individual_constraints_finetuned = brm(log_odds ~ Culture + Power + Freq + Len + no_final_stress + Intense + Percept + Lapse + (Culture + Power + Freq + Len + no_final_stress + Intense + Percept + Lapse | prompt) + ( 1 | Alpha),
#                        data = small_novel_genpref,
#                        #prior = prior_probs,
#                        iter = 10000,
#                        warmup = 5000,
#                        chains = 4,
#                        cores = 4,
#                        #control = list(adapt_delta=0.99, max_treedepth = 15),
#                        #control = list(max_treedepth = 20),
#                        file = '../Data/model_small_novel_individual_constraints_finetuned'
#                       )
#  

fixef(model_small_attested_genpref_finetuned)
fixef(model_small_novel_genpref_finetuned)
#fixef(model_small_novel_individual_constraints)
#car::vif(model_small_novel_individual_constraints_finetuned)



```

### testing with previous version of Qing's model

```{r}
model_data_finetuned_genpref_old = read_csv('../Data/FINETUNED_GENPREF_MODEL_PREVIOUS_BINOMIAL_PREFERENCES.csv') %>%
  mutate(log_odds = preference) %>%
  separate(binom, c('Word1', 'and', 'Word2'), remove = F, sep = ' ') %>%
  select(-and) %>%
  #mutate(across(2:3, tolower)) %>%
  left_join(corpus) %>%
  mutate(checkpoint = 'main') %>%
  mutate(y_vals = 0.02191943 + 0.23925834*Form +  0.24889543*Percept +  0.41836997*Culture +   0.25967334*Power +  0.01867604*Intense +  1.30365980*Icon +   0.08553552*Freq +  0.15241566*Len - 0.19381657*Lapse +  0.36019221*`*BStress`) %>%
  mutate(GenPref = 1/(1+exp(-1*y_vals))) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5) %>%
  ungroup() #%>%
  #filter(model == "qing-yao/genfreq-finetuned-ep10_seed-42_1e-4")


small_attested_genpref_old = model_data_finetuned_genpref_old %>%
  filter(Attested == 1) %>%
  mutate(CenteredOverallFreq = scale(log(OverallFreq))) 


small_novel_genpref_old = model_data_finetuned_genpref_old %>%
  filter(Attested == 0)

small_attested_genpref_old$prompt = factor(small_attested_genpref_old$prompt)
small_novel_genpref_old$prompt = factor(small_novel_genpref_old$prompt)

small_novel_genpref_old = small_novel_genpref_old %>%
  rename(no_final_stress = "*BStress")

small_attested_genpref_old = small_attested_genpref_old %>%
  rename(no_final_stress = "*BStress")



model_small_attested_genpref_finetuned_old = brm(log_odds ~ (GenPref + RelFreq + CenteredOverallFreq + GenPref:CenteredOverallFreq + RelFreq:CenteredOverallFreq) + (GenPref | prompt) + (1 | Alpha),
                       data = small_attested_genpref_old,
                       #prior = prior_probs,
                       iter = 10000,
                       warmup = 5000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/model_small_attested_genpref_finetuned_old'
                      )


model_small_novel_genpref_finetuned_old = brm(log_odds ~ GenPref + (GenPref | prompt) + (1 | Alpha),
                       data = small_novel_genpref_old,
                       #prior = prior_probs,
                       iter = 10000,
                       warmup = 5000,
                       chains = 4,
                       
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       #control = list(max_treedepth = 20),
                       file = '../Data/model_small_novel_genpref_finetuned_old'
                      )


### Vif then backward model selection

# model_small_novel_individual_constraints_finetuned = brm(log_odds ~ Culture + Power + Freq + Len + no_final_stress + Intense + Percept + Lapse + (Culture + Power + Freq + Len + no_final_stress + Intense + Percept + Lapse | prompt) + ( 1 | Alpha),
#                        data = small_novel_genpref,
#                        #prior = prior_probs,
#                        iter = 10000,
#                        warmup = 5000,
#                        chains = 4,
#                        cores = 4,
#                        #control = list(adapt_delta=0.99, max_treedepth = 15),
#                        #control = list(max_treedepth = 20),
#                        file = '../Data/model_small_novel_individual_constraints_finetuned'
#                       )
#  

fixef(model_small_attested_genpref_finetuned_old)
fixef(model_small_novel_genpref_finetuned_old)
```

### genpref 1 epoch

```{r}
options(contrasts = c("contr.sum","contr.sum"))

corpus = read_csv('../Data/nonce_and_attested_binoms.csv')

model_data_finetuned_genpref_1epoch =
  read_csv('../Data/FINETUNED_GENPREF_1EPOCH_MODEL_BINOMIAL_PREFERENCES.csv') %>%
  mutate(log_odds = preference) %>%
  separate(binom, c('Word1','and','Word2'), remove = FALSE, sep = ' ') %>%
  select(-and) %>%
  left_join(corpus) %>%
  mutate(
    checkpoint = '1epoch',
    y_vals = 0.02191943 + 0.23925834*Form + 0.24889543*Percept +
             0.41836997*Culture + 0.25967334*Power + 0.01867604*Intense +
             1.30365980*Icon + 0.08553552*Freq + 0.15241566*Len -
             0.19381657*Lapse + 0.36019221*`*BStress`,
    GenPref = plogis(y_vals) - 0.5,
    RelFreq = RelFreq - 0.5
  ) %>%
  ungroup()

small_attested_genpref_1epoch =
  model_data_finetuned_genpref_1epoch %>%
  filter(Attested == 1) %>%
  mutate(CenteredOverallFreq = scale(log(OverallFreq)))

small_novel_genpref_1epoch =
  model_data_finetuned_genpref_1epoch %>%
  filter(Attested == 0)

small_attested_genpref_1epoch$prompt = factor(small_attested_genpref_1epoch$prompt)
small_novel_genpref_1epoch$prompt    = factor(small_novel_genpref_1epoch$prompt)

small_attested_genpref_1epoch =
  small_attested_genpref_1epoch %>%
  rename(no_final_stress = "*BStress")

small_novel_genpref_1epoch =
  small_novel_genpref_1epoch %>%
  rename(no_final_stress = "*BStress")

model_small_attested_genpref_finetuned_1epoch = brm(
  log_odds ~
    (GenPref + RelFreq + CenteredOverallFreq +
     GenPref:CenteredOverallFreq + RelFreq:CenteredOverallFreq) +
    (GenPref | prompt) + (1 | Alpha),
  data   = small_attested_genpref_1epoch,
  iter   = 10000,
  warmup = 5000,
  chains = 4,
  cores  = 4,
  control = list(max_treedepth = 20),
  file   = '../Data/model_small_attested_genpref_finetuned_1epoch'
)

model_small_novel_genpref_finetuned_1epoch = brm(
  log_odds ~ GenPref + (GenPref | prompt) + (1 | Alpha),
  data   = small_novel_genpref_1epoch,
  iter   = 10000,
  warmup = 5000,
  chains = 4,
  cores  = 4,
  file   = '../Data/model_small_novel_genpref_finetuned_1epoch'
)

fixef(model_small_attested_genpref_finetuned_1epoch)
fixef(model_small_novel_genpref_finetuned_1epoch)

```


## Finetuned on RelFreq

```{r}
corpus = read_csv('../Data/nonce_and_attested_binoms.csv')

model_data_finetuned_relfreq = read_csv('../Data/FINETUNED_RELFREQ_MODEL_BINOMIAL_PREFERENCES.csv') %>%
  mutate(log_odds = preference) %>%
  separate(binom, c('Word1', 'and', 'Word2'), remove = F, sep = ' ') %>%
  select(-and) %>%
  #mutate(across(2:3, tolower)) %>%
  left_join(corpus) %>%
  mutate(checkpoint = 'main') %>%
  mutate(y_vals = 0.02191943 + 0.23925834*Form +  0.24889543*Percept +  0.41836997*Culture +   0.25967334*Power +  0.01867604*Intense +  1.30365980*Icon +   0.08553552*Freq +  0.15241566*Len - 0.19381657*Lapse +  0.36019221*`*BStress`) %>%
  mutate(GenPref = 1/(1+exp(-1*y_vals))) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5) %>%
  ungroup() 


small_attested_relfreq = model_data_finetuned_relfreq %>%
  filter(Attested == 1) %>%
  mutate(CenteredOverallFreq = scale(log(OverallFreq))) 


small_novel_relfreq = model_data_finetuned_relfreq %>%
  filter(Attested == 0)

small_attested_relfreq$prompt = factor(small_attested_relfreq$prompt)
small_novel_relfreq$prompt = factor(small_novel_relfreq$prompt)

small_novel_relfreq = small_novel_relfreq %>%
  rename(no_final_stress = "*BStress")

small_attested_relfreq = small_attested_relfreq %>%
  rename(no_final_stress = "*BStress")



model_small_attested_relfreq_finetuned = brm(log_odds ~ (GenPref + RelFreq + CenteredOverallFreq + GenPref:CenteredOverallFreq + RelFreq:CenteredOverallFreq) + (GenPref | prompt) + (1 | Alpha),
                       data = small_attested_relfreq,
                       #prior = prior_probs,
                       iter = 10000,
                       warmup = 5000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/model_small_attested_relfreq_finetuned'
                      )


model_small_novel_relfreq_finetuned = brm(log_odds ~ GenPref + (GenPref | prompt) + (1 | Alpha),
                       data = small_novel_relfreq,
                       #prior = prior_probs,
                       iter = 10000,
                       warmup = 5000,
                       chains = 4,
                       
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       #control = list(max_treedepth = 20),
                       file = '../Data/model_small_novel_relfreq_finetuned'
                      )


### Vif then backward model selection

# model_small_novel_individual_constraints_finetuned = brm(log_odds ~ Culture + Power + Freq + Len + no_final_stress + Intense + Percept + Lapse + (Culture + Power + Freq + Len + no_final_stress + Intense + Percept + Lapse | prompt) + ( 1 | Alpha),
#                        data = small_novel_genpref,
#                        #prior = prior_probs,
#                        iter = 10000,
#                        warmup = 5000,
#                        chains = 4,
#                        cores = 4,
#                        #control = list(adapt_delta=0.99, max_treedepth = 15),
#                        #control = list(max_treedepth = 20),
#                        file = '../Data/model_small_novel_individual_constraints_finetuned'
#                       )
#  

fixef(model_small_attested_relfreq_finetuned)
fixef(model_small_novel_relfreq_finetuned)
```
### RelFreq 1 epoch

```{r}
options(contrasts = c("contr.sum","contr.sum"))

corpus = read_csv('../Data/nonce_and_attested_binoms.csv')

model_data_finetuned_relfreq_1epoch =
  read_csv('../Data/FINETUNED_RELFREQ_1EPOCH_MODEL_BINOMIAL_PREFERENCES.csv') %>%
  mutate(log_odds = preference) %>%
  separate(binom, c('Word1','and','Word2'), remove = FALSE, sep = ' ') %>%
  select(-and) %>%
  left_join(corpus) %>%
  mutate(
    checkpoint = '1epoch',
    y_vals = 0.02191943 + 0.23925834*Form + 0.24889543*Percept +
             0.41836997*Culture + 0.25967334*Power + 0.01867604*Intense +
             1.30365980*Icon + 0.08553552*Freq + 0.15241566*Len -
             0.19381657*Lapse + 0.36019221*`*BStress`,
    GenPref = plogis(y_vals) - 0.5,
    RelFreq = RelFreq - 0.5
  ) %>%
  ungroup()

small_attested_relfreq_1epoch =
  model_data_finetuned_relfreq_1epoch %>%
  filter(Attested == 1) %>%
  mutate(CenteredOverallFreq = scale(log(OverallFreq)))

small_novel_relfreq_1epoch =
  model_data_finetuned_relfreq_1epoch %>%
  filter(Attested == 0)

small_attested_relfreq_1epoch$prompt = factor(small_attested_relfreq_1epoch$prompt)
small_novel_relfreq_1epoch$prompt    = factor(small_novel_relfreq_1epoch$prompt)

small_attested_relfreq_1epoch =
  small_attested_relfreq_1epoch %>%
  rename(no_final_stress = "*BStress")

small_novel_relfreq_1epoch =
  small_novel_relfreq_1epoch %>%
  rename(no_final_stress = "*BStress")

model_small_attested_relfreq_finetuned_1epoch = brm(
  log_odds ~
    (GenPref + RelFreq + CenteredOverallFreq +
     GenPref:CenteredOverallFreq + RelFreq:CenteredOverallFreq) +
    (GenPref | prompt) + (1 | Alpha),
  data   = small_attested_relfreq_1epoch,
  iter   = 10000,
  warmup = 5000,
  chains = 4,
  cores  = 4,
  control = list(max_treedepth = 20),
  file   = '../Data/model_small_attested_relfreq_finetuned_1epoch'
)

model_small_novel_relfreq_finetuned_1epoch = brm(
  log_odds ~ GenPref + (GenPref | prompt) + (1 | Alpha),
  data   = small_novel_relfreq_1epoch,
  iter   = 10000,
  warmup = 5000,
  chains = 4,
  cores  = 4,
  file   = '../Data/model_small_novel_relfreq_finetuned_1epoch'
)

fixef(model_small_attested_relfreq_finetuned_1epoch)
fixef(model_small_novel_relfreq_finetuned_1epoch)

```


## Finetuned on Non-binomials


```{r}
corpus = read_csv('../Data/nonce_and_attested_binoms.csv')

model_data_finetuned_control = read_csv('../Data/FINETUNED_CONTROL_MODEL_BINOMIAL_PREFERENCES.csv') %>%
  mutate(log_odds = preference) %>%
  separate(binom, c('Word1', 'and', 'Word2'), remove = F, sep = ' ') %>%
  select(-and) %>%
  #mutate(across(2:3, tolower)) %>%
  left_join(corpus) %>%
  mutate(checkpoint = 'main') %>%
  mutate(y_vals = 0.02191943 + 0.23925834*Form +  0.24889543*Percept +  0.41836997*Culture +   0.25967334*Power +  0.01867604*Intense +  1.30365980*Icon +   0.08553552*Freq +  0.15241566*Len - 0.19381657*Lapse +  0.36019221*`*BStress`) %>%
  mutate(GenPref = 1/(1+exp(-1*y_vals))) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5) %>%
  ungroup() 


small_attested_control= model_data_finetuned_control %>%
  filter(Attested == 1) %>%
  mutate(CenteredOverallFreq = scale(log(OverallFreq))) 


small_novel_control = model_data_finetuned_control %>%
  filter(Attested == 0)

small_attested_control$prompt = factor(small_attested_control$prompt)
small_novel_control$prompt = factor(small_novel_control$prompt)

small_novel_control = small_novel_control %>%
  rename(no_final_stress = "*BStress")

small_attested_control = small_attested_control %>%
  rename(no_final_stress = "*BStress")



model_small_attested_control_finetuned = brm(log_odds ~ (GenPref + RelFreq + CenteredOverallFreq + GenPref:CenteredOverallFreq + RelFreq:CenteredOverallFreq) + (GenPref | prompt) + (1 | Alpha),
                       data = small_attested_control,
                       #prior = prior_probs,
                       iter = 10000,
                       warmup = 5000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/model_small_attested_control_finetuned'
                      )


model_small_novel_control_finetuned = brm(log_odds ~ GenPref + (GenPref | prompt) + (1 | Alpha),
                       data = small_novel_control,
                       #prior = prior_probs,
                       iter = 10000,
                       warmup = 5000,
                       chains = 4,
                       
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       #control = list(max_treedepth = 20),
                       file = '../Data/model_small_novel_control_finetuned'
                      )


### Vif then backward model selection

# model_small_novel_individual_constraints_finetuned = brm(log_odds ~ Culture + Power + Freq + Len + no_final_stress + Intense + Percept + Lapse + (Culture + Power + Freq + Len + no_final_stress + Intense + Percept + Lapse | prompt) + ( 1 | Alpha),
#                        data = small_novel_genpref,
#                        #prior = prior_probs,
#                        iter = 10000,
#                        warmup = 5000,
#                        chains = 4,
#                        cores = 4,
#                        #control = list(adapt_delta=0.99, max_treedepth = 15),
#                        #control = list(max_treedepth = 20),
#                        file = '../Data/model_small_novel_individual_constraints_finetuned'
#                       )
#  

fixef(model_small_attested_control_finetuned)
fixef(model_small_novel_control_finetuned)
```
### control non-binoms 1 epoch

```{r}
options(contrasts = c("contr.sum","contr.sum"))

corpus = read_csv('../Data/nonce_and_attested_binoms.csv')

model_data_finetuned_control_1epoch =
  read_csv('../Data/FINETUNED_CONTROL_1EPOCH_MODEL_BINOMIAL_PREFERENCES.csv') %>%
  mutate(log_odds = preference) %>%
  separate(binom, c('Word1','and','Word2'), remove = FALSE, sep = ' ') %>%
  select(-and) %>%
  left_join(corpus) %>%
  mutate(
    checkpoint = '1epoch',
    y_vals = 0.02191943 + 0.23925834*Form + 0.24889543*Percept +
             0.41836997*Culture + 0.25967334*Power + 0.01867604*Intense +
             1.30365980*Icon + 0.08553552*Freq + 0.15241566*Len -
             0.19381657*Lapse + 0.36019221*`*BStress`,
    GenPref = plogis(y_vals) - 0.5,
    RelFreq = RelFreq - 0.5
  ) %>%
  ungroup()

small_attested_control_1epoch =
  model_data_finetuned_control_1epoch %>%
  filter(Attested == 1) %>%
  mutate(CenteredOverallFreq = scale(log(OverallFreq)))

small_novel_control_1epoch =
  model_data_finetuned_control_1epoch %>%
  filter(Attested == 0)

small_attested_control_1epoch$prompt = factor(small_attested_control_1epoch$prompt)
small_novel_control_1epoch$prompt    = factor(small_novel_control_1epoch$prompt)

small_attested_control_1epoch =
  small_attested_control_1epoch %>%
  rename(no_final_stress = "*BStress")

small_novel_control_1epoch =
  small_novel_control_1epoch %>%
  rename(no_final_stress = "*BStress")

model_small_attested_control_finetuned_1epoch = brm(
  log_odds ~
    (GenPref + RelFreq + CenteredOverallFreq +
     GenPref:CenteredOverallFreq + RelFreq:CenteredOverallFreq) +
    (GenPref | prompt) + (1 | Alpha),
  data   = small_attested_control_1epoch,
  iter   = 10000,
  warmup = 5000,
  chains = 4,
  cores  = 4,
  control = list(max_treedepth = 20),
  file   = '../Data/model_small_attested_control_finetuned_1epoch'
)

model_small_novel_control_finetuned_1epoch = brm(
  log_odds ~ GenPref + (GenPref | prompt) + (1 | Alpha),
  data   = small_novel_control_1epoch,
  iter   = 10000,
  warmup = 5000,
  chains = 4,
  cores  = 4,
  file   = '../Data/model_small_novel_control_finetuned_1epoch'
)

fixef(model_small_attested_control_finetuned_1epoch)
fixef(model_small_novel_control_finetuned_1epoch)

```


# Comparing to human predictions

## baseline for novel and attested

```{r}

# all_human_data = nonce_data
all_human_data = read_csv('../Human Data and Analyses/all_human_data.csv') %>%
  mutate(Attested = ifelse(
    OverallFreq == 0, 0, 1
  )) %>%
  select(participant, resp, Word1, Word2, Alpha, Nonalpha, OverallFreq, Word1_freq, Word2_freq, Form, Percept, Culture, Power, Intense, Icon, Freq, Len, Lapse, "*BStress", RelFreq, GenPref, Attested) %>%
  mutate(y_vals = 0.02191943 + 0.23925834*Form +  0.24889543*Percept +  0.41836997*Culture +   0.25967334*Power +  0.01867604*Intense +  1.30365980*Icon +   0.08553552*Freq +  0.15241566*Len - 0.19381657*Lapse +  0.36019221*`*BStress`) %>%
  mutate(GenPref = 1/(1+exp(-1*y_vals))) %>%
  mutate(GenPref = GenPref - 0.5)

all_human_data = all_human_data %>%
  mutate(resp_binary = case_when(
    resp == 'alpha' ~ 1,
    resp == 'nonalpha' ~ 0
  ))

all_human_data_novel = all_human_data %>%
  filter(Attested == 0)

all_human_data_attested = all_human_data %>%
  filter(Attested == 1)

prior_probs <- c(
  prior(normal(0, 1), class = "Intercept"),
  prior(student_t(3, 0, 1), class = "sd", group = "Alpha"),
  prior(student_t(3, 0, 1), class = "sd", group = "prompt"),
  prior(student_t(3, 0, 1), class = "sigma")
)

baseline_model_data_novel = baseline_model_data %>% 
  filter(Attested == 0)

baseline_model_data_attested = baseline_model_data %>% 
  filter(Attested == 1)

baseline_item_preds_novel = brm(log_odds ~ 1 + (1 | Alpha) + (1 | prompt),
                       data = baseline_model_data_novel,
                       prior = prior_probs,
                       iter =  18000,
                       warmup = 9000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       #control = list(max_treedepth = 20),
                       file = '../Data/baseline_item_preds_novel'
                      )

baseline_item_preds_attested = brm(log_odds ~ 1 + (1 | Alpha) + (1 | prompt),
                       data = baseline_model_data_attested,
                       prior = prior_probs,
                       iter =  30000,
                       warmup = 15000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       #control = list(max_treedepth = 20),
                       file = '../Data/baseline_item_preds_attested'
                      )


newdata_novel = data.frame(
  Alpha = unique(baseline_model_data_novel$Alpha),
  prompt = NA
)


fitB_novel = fitted(
  baseline_item_preds_novel,
  newdata = newdata_novel,
  re_formula = ~(1 | Alpha),
  summary = TRUE
)

item_df_baseline_novel = data.frame(
  Alpha = newdata_novel$Alpha,
  item_logodds_baseline = fitB_novel[, "Estimate"],
  item_lo_baseline      = fitB_novel[, "Q2.5"],
  item_hi_baseline      = fitB_novel[, "Q97.5"]
)


newdata_attested = data.frame(
  Alpha = unique(baseline_model_data_attested$Alpha),
  prompt = NA
)

fitB_attested = fitted(
  baseline_item_preds_attested,
  newdata = newdata_attested,
  re_formula = ~(1 | Alpha),
  summary = TRUE
)

item_df_baseline_attested = data.frame(
  Alpha = newdata_attested$Alpha,
  item_logodds_baseline = fitB_attested[, "Estimate"],
  item_lo_baseline      = fitB_attested[, "Q2.5"],
  item_hi_baseline      = fitB_attested[, "Q97.5"]
)

human_data_novel = all_human_data_novel %>%
  left_join(item_df_baseline_novel, by = 'Alpha')

human_data_attested = all_human_data_attested %>%
  left_join(item_df_baseline_attested, by = 'Alpha')


prior_probs2 <- c(
  # Fixed effects
  prior(normal(0, 1), class = "Intercept"),
  prior(normal(0, 1), class = "b", coef = "item_logodds_baseline"),

  # Random-effect standard deviations
  prior(student_t(3, 0, 1), class = "sd", group = "participant"),
  prior(student_t(3, 0, 1), class = "sd", group = "Alpha")
)

human_data_novel_baseline = brm(
  resp_binary ~ item_logodds_baseline + (1 | participant) + (1 | Alpha),
  data = human_data_novel,
  family = bernoulli(link = "logit"),
  chains = 4,   
  cores = 4,
  iter = 6000,  
  warmup = 3000,
  save_pars = save_pars(all = TRUE),
  prior = prior_probs2,
  #control = list(adapt_delta=0.99, max_treedepth = 20),
  file = '../Data/human_data_novel_baseline'
)

human_data_novel_baseline = add_criterion(human_data_novel_baseline, 'loo')

human_data_attested_baseline = brm(
  resp_binary ~ item_logodds_baseline + (1 | participant) + (1 | Alpha),
  data = human_data_attested,
  family = bernoulli(link = "logit"),
  chains = 4,   
  cores = 4,
  iter = 6000,  
  warmup = 3000,
  save_pars = save_pars(all = TRUE),
  prior = prior_probs2,
  #control = list(adapt_delta=0.99, max_treedepth = 20),
  file = '../Data/human_data_attested_baseline'
)

human_data_attested_baseline = add_criterion(human_data_attested_baseline, 'loo')


```

## Finetuned Genpref 


```{r}
genpref_model_data_novel = model_data_finetuned_genpref %>%
  filter(Attested == 0)

genpref_model_data_attested = model_data_finetuned_genpref %>%
  filter(Attested == 1)

genpref_item_preds_novel = brm(log_odds ~ 1 + (1 | Alpha) + (1 | prompt),
                       data = genpref_model_data_novel,
                       prior = prior_probs,
                       iter =  18000,
                       warmup = 9000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       #control = list(max_treedepth = 20),
                       file = '../Data/genpref_item_preds_novel'
                      )

genpref_item_preds_attested = brm(log_odds ~ 1 + (1 | Alpha) + (1 | prompt),
                       data = genpref_model_data_attested,
                       prior = prior_probs,
                       iter =  20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       #control = list(max_treedepth = 20),
                       file = '../Data/genpref_item_preds_attested'
                      )

newdata_novel_genpref = data.frame(
  Alpha = unique(genpref_model_data_novel$Alpha),
  prompt = NA
)

fitG_novel = fitted(
  genpref_item_preds_novel,
  newdata = newdata_novel_genpref,
  re_formula = ~ (1 | Alpha),
  summary = TRUE
)

item_df_genpref_novel = data.frame(
  Alpha = newdata_novel_genpref$Alpha,
  item_logodds_genpref = fitG_novel[, "Estimate"],
  item_lo_genpref      = fitG_novel[, "Q2.5"],
  item_hi_genpref      = fitG_novel[, "Q97.5"]
)

newdata_attested_genpref = data.frame(
  Alpha = unique(genpref_model_data_attested$Alpha),
  prompt = NA
)

fitG_attested = fitted(
  genpref_item_preds_attested,
  newdata = newdata_attested_genpref,
  re_formula = ~(1 | Alpha),
  summary = TRUE
)

item_df_genpref_attested = data.frame(
  Alpha = newdata_attested_genpref$Alpha,
  item_logodds_genpref = fitG_attested[, "Estimate"],
  item_lo_genpref      = fitG_attested[, "Q2.5"],
  item_hi_genpref      = fitG_attested[, "Q97.5"]
)

human_data_novel_genpref = all_human_data_novel %>%
  left_join(item_df_genpref_novel, by = 'Alpha')

human_data_attested_genpref = all_human_data_attested %>%
  left_join(item_df_genpref_attested, by = 'Alpha')
prior_probs3 <- c(
  # Fixed effects
  prior(normal(0, 1), class = "Intercept"),
  prior(normal(0, 1), class = "b", coef = "item_logodds_genpref"),
  # Random-effect standard deviations
  prior(student_t(3, 0, 1), class = "sd", group = "participant"),
  prior(student_t(3, 0, 1), class = "sd", group = "Alpha")
)
human_data_novel_genpref_model = brm(
  resp_binary ~ item_logodds_genpref + (1 | participant) + (1 | Alpha),
  data = human_data_novel_genpref,
  family = bernoulli(link = "logit"),
  chains = 4,   
  cores = 4,
  iter = 6000,  
  warmup = 3000,
  save_pars = save_pars(all = TRUE),
  prior = prior_probs3,
  #control = list(adapt_delta=0.99, max_treedepth = 20),
  file = '../Data/human_data_novel_genpref_model'
)
human_data_novel_genpref_model = add_criterion(human_data_novel_genpref_model, 'loo')

human_data_attested_genpref_model = brm(
  resp_binary ~ item_logodds_genpref + (1 | participant) + (1 | Alpha),
  data = human_data_attested_genpref,
  family = bernoulli(link = "logit"),
  chains = 4,   
  cores = 4,
  iter = 6000,  
  warmup = 3000,
  save_pars = save_pars(all = TRUE),
  prior = prior_probs3,
  #control = list(adapt_delta=0.99, max_treedepth = 20),
  file = '../Data/human_data_attested_genpref_model'
)

human_data_attested_genpref_model = add_criterion(human_data_attested_genpref_model, 'loo')

loo_results_novel = loo_compare(
  human_data_novel_baseline,
  human_data_novel_genpref_model
)

loo_results_attested = loo_compare(
  human_data_attested_baseline,
  human_data_attested_genpref_model
)

```

### GenPref model with fewer epochs

```{r}
# ==========================================================
# Compare "old finetuned genpref" model predictions to humans
# (parallel to your genpref_model_data_* pipeline)
# ==========================================================

# --------------------------
# Split old finetuned model data into novel vs attested
# --------------------------
genpref_old_model_data_novel <- model_data_finetuned_genpref_old %>%
  filter(Attested == 0)

genpref_old_model_data_attested <- model_data_finetuned_genpref_old %>%
  filter(Attested == 1)

# --------------------------
# Fit item-prediction models (log_odds ~ 1 + REs)
# --------------------------
genpref_old_item_preds_novel <- brm(
  log_odds ~ 1 + (1 | Alpha) + (1 | prompt),
  data   = genpref_old_model_data_novel,
  prior  = prior_probs,
  iter   = 18000,
  warmup = 9000,
  chains = 4,
  cores  = 4,
  file   = "../Data/genpref_old_item_preds_novel"
)

genpref_old_item_preds_attested <- brm(
  log_odds ~ 1 + (1 | Alpha) + (1 | prompt),
  data   = genpref_old_model_data_attested,
  prior  = prior_probs,
  iter   = 20000,
  warmup = 10000,
  chains = 4,
  cores  = 4,
  file   = "../Data/genpref_old_item_preds_attested"
)

# --------------------------
# Extract per-item (Alpha) predicted log-odds (marginalizing prompt)
# --------------------------
newdata_novel_genpref_old <- data.frame(
  Alpha  = unique(genpref_old_model_data_novel$Alpha),
  prompt = NA
)

fitG_old_novel <- fitted(
  genpref_old_item_preds_novel,
  newdata     = newdata_novel_genpref_old,
  re_formula  = ~(1 | Alpha),
  summary     = TRUE
)

item_df_genpref_old_novel <- data.frame(
  Alpha                 = newdata_novel_genpref_old$Alpha,
  item_logodds_genpref_old = fitG_old_novel[, "Estimate"],
  item_lo_genpref_old      = fitG_old_novel[, "Q2.5"],
  item_hi_genpref_old      = fitG_old_novel[, "Q97.5"]
)

newdata_attested_genpref_old <- data.frame(
  Alpha  = unique(genpref_old_model_data_attested$Alpha),
  prompt = NA
)

fitG_old_attested <- fitted(
  genpref_old_item_preds_attested,
  newdata     = newdata_attested_genpref_old,
  re_formula  = ~(1 | Alpha),
  summary     = TRUE
)

item_df_genpref_old_attested <- data.frame(
  Alpha                 = newdata_attested_genpref_old$Alpha,
  item_logodds_genpref_old = fitG_old_attested[, "Estimate"],
  item_lo_genpref_old      = fitG_old_attested[, "Q2.5"],
  item_hi_genpref_old      = fitG_old_attested[, "Q97.5"]
)

# --------------------------
# Join to human data
# --------------------------
human_data_novel_genpref_old <- all_human_data_novel %>%
  left_join(item_df_genpref_old_novel, by = "Alpha")

human_data_attested_genpref_old <- all_human_data_attested %>%
  left_join(item_df_genpref_old_attested, by = "Alpha")

# --------------------------
# Priors for the human-choice model using the OLD item log-odds predictor
# --------------------------
prior_probs_old <- c(
  prior(normal(0, 1), class = "Intercept"),
  prior(normal(0, 1), class = "b", coef = "item_logodds_genpref_old"),
  prior(student_t(3, 0, 1), class = "sd", group = "participant"),
  prior(student_t(3, 0, 1), class = "sd", group = "Alpha")
)

# --------------------------
# Fit human models (novel + attested)
# --------------------------
human_data_novel_genpref_old_model <- brm(
  resp_binary ~ item_logodds_genpref_old + (1 | participant) + (1 | Alpha),
  data     = human_data_novel_genpref_old,
  family   = bernoulli(link = "logit"),
  chains   = 4,
  cores    = 4,
  iter     = 6000,
  warmup   = 3000,
  save_pars = save_pars(all = TRUE),
  prior    = prior_probs_old,
  file     = "../Data/human_data_novel_genpref_old_model"
) %>%
  add_criterion("loo")

human_data_attested_genpref_old_model <- brm(
  resp_binary ~ item_logodds_genpref_old + (1 | participant) + (1 | Alpha),
  data     = human_data_attested_genpref_old,
  family   = bernoulli(link = "logit"),
  chains   = 4,
  cores    = 4,
  iter     = 6000,
  warmup   = 3000,
  save_pars = save_pars(all = TRUE),
  prior    = prior_probs_old,
  file     = "../Data/human_data_attested_genpref_old_model"
) %>%
  add_criterion("loo")

# --------------------------
# LOO comparisons against your existing baseline human models
# (assumes human_data_novel_baseline and human_data_attested_baseline already exist + have loo)
# --------------------------
loo_results_novel_genpref_old <- loo_compare(
  human_data_novel_baseline,
  human_data_novel_genpref_old_model
)

loo_results_attested_genpref_old <- loo_compare(
  human_data_attested_baseline,
  human_data_attested_genpref_old_model
)

loo_results_novel_genpref_old
loo_results_attested_genpref_old


```

### Finetuned on Genpref 1 epoch

```{r}
genpref_1epoch_model_data = read_csv('../Data/FINETUNED_GENPREF_1EPOCH_MODEL_BINOMIAL_PREFERENCES.csv') %>%
  mutate(log_odds = preference) %>%
  separate(binom, c('Word1', 'and', 'Word2'), remove = FALSE, sep = ' ') %>%
  select(-and) %>%
  left_join(corpus) %>%
  mutate(
    y_vals = 0.02191943 + 0.23925834*Form + 0.24889543*Percept +
             0.41836997*Culture + 0.25967334*Power + 0.01867604*Intense +
             1.30365980*Icon + 0.08553552*Freq + 0.15241566*Len -
             0.19381657*Lapse + 0.36019221*`*BStress`,
    GenPref = plogis(y_vals) - 0.5,
    RelFreq = RelFreq - 0.5
  )

genpref_1epoch_model_data_novel    = genpref_1epoch_model_data %>% filter(Attested == 0)
genpref_1epoch_model_data_attested = genpref_1epoch_model_data %>% filter(Attested == 1)

genpref_1epoch_item_preds_novel = brm(
  log_odds ~ 1 + (1 | Alpha) + (1 | prompt),
  data   = genpref_1epoch_model_data_novel,
  prior  = prior_probs,
  iter   = 18000,
  warmup = 9000,
  chains = 4,
  cores  = 4,
  file   = '../Data/genpref_1epoch_item_preds_novel'
)

genpref_1epoch_item_preds_attested = brm(
  log_odds ~ 1 + (1 | Alpha) + (1 | prompt),
  data   = genpref_1epoch_model_data_attested,
  prior  = prior_probs,
  iter   = 20000,
  warmup = 10000,
  chains = 4,
  cores  = 4,
  file   = '../Data/genpref_1epoch_item_preds_attested'
)

# ---- extract item-level predictions ----
newdata_novel_genpref_1epoch = data.frame(
  Alpha  = unique(genpref_1epoch_model_data_novel$Alpha),
  prompt = NA
)

fitG_1epoch_novel = fitted(
  genpref_1epoch_item_preds_novel,
  newdata    = newdata_novel_genpref_1epoch,
  re_formula = ~(1 | Alpha),
  summary    = TRUE
)

item_df_genpref_1epoch_novel = data.frame(
  Alpha = newdata_novel_genpref_1epoch$Alpha,
  item_logodds_genpref_1epoch = fitG_1epoch_novel[, "Estimate"]
)

newdata_attested_genpref_1epoch = data.frame(
  Alpha  = unique(genpref_1epoch_model_data_attested$Alpha),
  prompt = NA
)

fitG_1epoch_attested = fitted(
  genpref_1epoch_item_preds_attested,
  newdata    = newdata_attested_genpref_1epoch,
  re_formula = ~(1 | Alpha),
  summary    = TRUE
)

item_df_genpref_1epoch_attested = data.frame(
  Alpha = newdata_attested_genpref_1epoch$Alpha,
  item_logodds_genpref_1epoch = fitG_1epoch_attested[, "Estimate"]
)

human_data_novel_genpref_1epoch = all_human_data_novel %>%
  left_join(item_df_genpref_1epoch_novel, by = "Alpha")

human_data_attested_genpref_1epoch = all_human_data_attested %>%
  left_join(item_df_genpref_1epoch_attested, by = "Alpha")

prior_probs_genpref_1epoch <- c(
  prior(normal(0, 1), class = "Intercept"),
  prior(normal(0, 1), class = "b", coef = "item_logodds_genpref_1epoch"),
  prior(student_t(3, 0, 1), class = "sd", group = "participant"),
  prior(student_t(3, 0, 1), class = "sd", group = "Alpha")
)

human_data_novel_genpref_1epoch_model = brm(
  resp_binary ~ item_logodds_genpref_1epoch + (1 | participant) + (1 | Alpha),
  data   = human_data_novel_genpref_1epoch,
  family = bernoulli(),
  prior  = prior_probs_genpref_1epoch,
  iter   = 6000,
  warmup = 3000,
  chains = 4,
  cores  = 4,
  file   = '../Data/human_data_novel_genpref_1epoch_model'
) %>% add_criterion('loo')

human_data_attested_genpref_1epoch_model = brm(
  resp_binary ~ item_logodds_genpref_1epoch + (1 | participant) + (1 | Alpha),
  data   = human_data_attested_genpref_1epoch,
  family = bernoulli(),
  prior  = prior_probs_genpref_1epoch,
  iter   = 6000,
  warmup = 3000,
  chains = 4,
  cores  = 4,
  file   = '../Data/human_data_attested_genpref_1epoch_model'
) %>% add_criterion('loo')

```


## Finetuned on RelFreq

```{r}
relfreq_model_data_novel = model_data_finetuned_relfreq %>%
  filter(Attested == 0)

relfreq_model_data_attested = model_data_finetuned_relfreq %>%
  filter(Attested == 1)

relfreq_item_preds_novel = brm(log_odds ~ 1 + (1 | Alpha) + (1 | prompt),
                       data = relfreq_model_data_novel,
                       prior = prior_probs,
                       iter =  18000,
                       warmup = 9000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       #control = list(max_treedepth = 20),
                       file = '../Data/relfreq_item_preds_novel'
                      )

relfreq_item_preds_attested = brm(log_odds ~ 1 + (1 | Alpha) + (1 | prompt),
                       data = relfreq_model_data_attested,
                       prior = prior_probs,
                       iter =  20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       #control = list(max_treedepth = 20),
                       file = '../Data/relfreq_item_preds_attested'
                      )

newdata_novel_relfreq = data.frame(
  Alpha = unique(relfreq_model_data_novel$Alpha),
  prompt = NA
)

fitR_novel = fitted(
  relfreq_item_preds_novel,
  newdata = newdata_novel_relfreq,
  re_formula = ~ (1 | Alpha),
  summary = TRUE
)

item_df_relfreq_novel = data.frame(
  Alpha = newdata_novel_relfreq$Alpha,
  item_logodds_relfreq = fitR_novel[, "Estimate"],
  item_lo_relfreq     = fitR_novel[, "Q2.5"],
  item_hi_relfreq      = fitR_novel[, "Q97.5"]
)

newdata_attested_relfreq = data.frame(
  Alpha = unique(relfreq_model_data_attested$Alpha),
  prompt = NA
)

fitR_attested = fitted(
  relfreq_item_preds_attested,
  newdata = newdata_attested_relfreq,
  re_formula = ~(1 | Alpha),
  summary = TRUE
)

item_df_relfreq_attested = data.frame(
  Alpha = newdata_attested_relfreq$Alpha,
  item_logodds_relfreq = fitR_attested[, "Estimate"],
  item_lo_relfreq      = fitR_attested[, "Q2.5"],
  item_hi_relfreq      = fitR_attested[, "Q97.5"]
)

human_data_novel_relfreq = all_human_data_novel %>%
  left_join(item_df_relfreq_novel, by = 'Alpha')

human_data_attested_relfreq = all_human_data_attested %>%
  left_join(item_df_relfreq_attested, by = 'Alpha')
prior_probs3 <- c(
  # Fixed effects
  prior(normal(0, 1), class = "Intercept"),
  prior(normal(0, 1), class = "b", coef = "item_logodds_relfreq"),
  # Random-effect standard deviations
  prior(student_t(3, 0, 1), class = "sd", group = "participant"),
  prior(student_t(3, 0, 1), class = "sd", group = "Alpha")
)
human_data_novel_relfreq_model = brm(
  resp_binary ~ item_logodds_relfreq + (1 | participant) + (1 | Alpha),
  data = human_data_novel_relfreq,
  family = bernoulli(link = "logit"),
  chains = 4,   
  cores = 4,
  iter = 6000,  
  warmup = 3000,
  save_pars = save_pars(all = TRUE),
  prior = prior_probs3,
  #control = list(adapt_delta=0.99, max_treedepth = 20),
  file = '../Data/human_data_novel_relfreq_model'
)
human_data_novel_relfreq_model = add_criterion(human_data_novel_relfreq_model, 'loo')

human_data_attested_relfreq_model = brm(
  resp_binary ~ item_logodds_relfreq + (1 | participant) + (1 | Alpha),
  data = human_data_attested_relfreq,
  family = bernoulli(link = "logit"),
  chains = 4,   
  cores = 4,
  iter = 6000,  
  warmup = 3000,
  save_pars = save_pars(all = TRUE),
  prior = prior_probs3,
  #control = list(adapt_delta=0.99, max_treedepth = 20),
  file = '../Data/human_data_attested_relfreq_model'
)

human_data_attested_relfreq_model = add_criterion(human_data_attested_relfreq_model, 'loo')

```
### Finetuned on RelFreq 1 epoch

```{r}
# --------------------------
# Load 1-epoch RelFreq model data
# --------------------------
relfreq_1epoch_model_data = read_csv(
  '../Data/FINETUNED_RELFREQ_1EPOCH_MODEL_BINOMIAL_PREFERENCES.csv'
) %>%
  mutate(log_odds = preference) %>%
  separate(binom, c('Word1', 'and', 'Word2'), remove = FALSE, sep = ' ') %>%
  select(-and) %>%
  left_join(corpus) %>%
  mutate(
    y_vals = 0.02191943 + 0.23925834*Form + 0.24889543*Percept +
             0.41836997*Culture + 0.25967334*Power + 0.01867604*Intense +
             1.30365980*Icon + 0.08553552*Freq + 0.15241566*Len -
             0.19381657*Lapse + 0.36019221*`*BStress`,
    GenPref = plogis(y_vals) - 0.5,
    RelFreq = RelFreq - 0.5
  )

relfreq_1epoch_model_data_novel =
  relfreq_1epoch_model_data %>% filter(Attested == 0)

relfreq_1epoch_model_data_attested =
  relfreq_1epoch_model_data %>% filter(Attested == 1)

# --------------------------
# Item-level models
# --------------------------
relfreq_1epoch_item_preds_novel = brm(
  log_odds ~ 1 + (1 | Alpha) + (1 | prompt),
  data   = relfreq_1epoch_model_data_novel,
  prior  = prior_probs,
  iter   = 18000,
  warmup = 9000,
  chains = 4,
  cores  = 4,
  file   = '../Data/relfreq_1epoch_item_preds_novel'
)

relfreq_1epoch_item_preds_attested = brm(
  log_odds ~ 1 + (1 | Alpha) + (1 | prompt),
  data   = relfreq_1epoch_model_data_attested,
  prior  = prior_probs,
  iter   = 20000,
  warmup = 10000,
  chains = 4,
  cores  = 4,
  file   = '../Data/relfreq_1epoch_item_preds_attested'
)

# --------------------------
# Extract item predictions
# --------------------------
newdata_novel_relfreq_1epoch = data.frame(
  Alpha  = unique(relfreq_1epoch_model_data_novel$Alpha),
  prompt = NA
)

fitR_1epoch_novel = fitted(
  relfreq_1epoch_item_preds_novel,
  newdata    = newdata_novel_relfreq_1epoch,
  re_formula = ~(1 | Alpha),
  summary    = TRUE
)

item_df_relfreq_1epoch_novel = data.frame(
  Alpha = newdata_novel_relfreq_1epoch$Alpha,
  item_logodds_relfreq_1epoch = fitR_1epoch_novel[, "Estimate"]
)

newdata_attested_relfreq_1epoch = data.frame(
  Alpha  = unique(relfreq_1epoch_model_data_attested$Alpha),
  prompt = NA
)

fitR_1epoch_attested = fitted(
  relfreq_1epoch_item_preds_attested,
  newdata    = newdata_attested_relfreq_1epoch,
  re_formula = ~(1 | Alpha),
  summary    = TRUE
)

item_df_relfreq_1epoch_attested = data.frame(
  Alpha = newdata_attested_relfreq_1epoch$Alpha,
  item_logodds_relfreq_1epoch = fitR_1epoch_attested[, "Estimate"]
)

# --------------------------
# Join to human data
# --------------------------
human_data_novel_relfreq_1epoch =
  all_human_data_novel %>%
  left_join(item_df_relfreq_1epoch_novel, by = "Alpha")

human_data_attested_relfreq_1epoch =
  all_human_data_attested %>%
  left_join(item_df_relfreq_1epoch_attested, by = "Alpha")

# --------------------------
# Human choice models
# --------------------------
prior_probs_relfreq_1epoch <- c(
  prior(normal(0, 1), class = "Intercept"),
  prior(normal(0, 1), class = "b", coef = "item_logodds_relfreq_1epoch"),
  prior(student_t(3, 0, 1), class = "sd", group = "participant"),
  prior(student_t(3, 0, 1), class = "sd", group = "Alpha")
)

human_data_novel_relfreq_1epoch_model = brm(
  resp_binary ~ item_logodds_relfreq_1epoch + (1 | participant) + (1 | Alpha),
  data   = human_data_novel_relfreq_1epoch,
  family = bernoulli(),
  prior  = prior_probs_relfreq_1epoch,
  iter   = 6000,
  warmup = 3000,
  chains = 4,
  cores  = 4,
  file   = '../Data/human_data_novel_relfreq_1epoch_model'
) %>% add_criterion("loo")

human_data_attested_relfreq_1epoch_model = brm(
  resp_binary ~ item_logodds_relfreq_1epoch + (1 | participant) + (1 | Alpha),
  data   = human_data_attested_relfreq_1epoch,
  family = bernoulli(),
  prior  = prior_probs_relfreq_1epoch,
  iter   = 6000,
  warmup = 3000,
  chains = 4,
  cores  = 4,
  file   = '../Data/human_data_attested_relfreq_1epoch_model'
) %>% add_criterion("loo")

```


## Finetuned on Non-binomial control

```{r}
control_model_data_novel = model_data_finetuned_control %>%
  filter(Attested == 0)

control_model_data_attested = model_data_finetuned_control %>%
  filter(Attested == 1)

control_item_preds_novel = brm(log_odds ~ 1 + (1 | Alpha) + (1 | prompt),
                       data = control_model_data_novel,
                       prior = prior_probs,
                       iter =  18000,
                       warmup = 9000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       #control = list(max_treedepth = 20),
                       file = '../Data/control_item_preds_novel'
                      )

control_item_preds_attested = brm(log_odds ~ 1 + (1 | Alpha) + (1 | prompt),
                       data = control_model_data_attested,
                       prior = prior_probs,
                       iter =  20000,
                       warmup = 10000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       #control = list(max_treedepth = 20),
                       file = '../Data/control_item_preds_attested'
                      )

newdata_novel_control = data.frame(
  Alpha = unique(control_model_data_novel$Alpha),
  prompt = NA
)

fitC_novel = fitted(
  control_item_preds_novel,
  newdata = newdata_novel_control,
  re_formula = ~ (1 | Alpha),
  summary = TRUE
)

item_df_control_novel = data.frame(
  Alpha = newdata_novel_control$Alpha,
  item_logodds_control = fitC_novel[, "Estimate"],
  item_lo_control      = fitC_novel[, "Q2.5"],
  item_hi_control      = fitC_novel[, "Q97.5"]
)

newdata_attested_control = data.frame(
  Alpha = unique(control_model_data_attested$Alpha),
  prompt = NA
)

fitC_attested = fitted(
  control_item_preds_attested,
  newdata = newdata_attested_control,
  re_formula = ~(1 | Alpha),
  summary = TRUE
)

item_df_control_attested = data.frame(
  Alpha = newdata_attested_control$Alpha,
  item_logodds_control = fitC_attested[, "Estimate"],
  item_lo_control      = fitC_attested[, "Q2.5"],
  item_hi_control      = fitC_attested[, "Q97.5"]
)

human_data_novel_control = all_human_data_novel %>%
  left_join(item_df_control_novel, by = 'Alpha')

human_data_attested_control = all_human_data_attested %>%
  left_join(item_df_control_attested, by = 'Alpha')
prior_probs3 <- c(
  # Fixed effects
  prior(normal(0, 1), class = "Intercept"),
  prior(normal(0, 1), class = "b", coef = "item_logodds_control"),
  # Random-effect standard deviations
  prior(student_t(3, 0, 1), class = "sd", group = "participant"),
  prior(student_t(3, 0, 1), class = "sd", group = "Alpha")
)
human_data_novel_control_model = brm(
  resp_binary ~ item_logodds_control + (1 | participant) + (1 | Alpha),
  data = human_data_novel_control,
  family = bernoulli(link = "logit"),
  chains = 4,   
  cores = 4,
  iter = 6000,  
  warmup = 3000,
  save_pars = save_pars(all = TRUE),
  prior = prior_probs3,
  #control = list(adapt_delta=0.99, max_treedepth = 20),
  file = '../Data/human_data_novel_control_model'
)
human_data_novel_control_model = add_criterion(human_data_novel_control_model, 'loo')

human_data_attested_control_model = brm(
  resp_binary ~ item_logodds_control + (1 | participant) + (1 | Alpha),
  data = human_data_attested_control,
  family = bernoulli(link = "logit"),
  chains = 4,   
  cores = 4,
  iter = 6000,  
  warmup = 3000,
  save_pars = save_pars(all = TRUE),
  prior = prior_probs3,
  #control = list(adapt_delta=0.99, max_treedepth = 20),
  file = '../Data/human_data_attested_control_model'
)

human_data_attested_control_model = add_criterion(human_data_attested_control_model, 'loo')

loo_results_novel = loo_compare(
  human_data_novel_baseline,
  human_data_novel_genpref_model,
  human_data_novel_relfreq_model,
  human_data_novel_control_model
)

loo_results_attested = loo_compare(
  human_data_attested_baseline,
  human_data_attested_genpref_model,
  
  human_data_attested_relfreq_model,
  human_data_attested_control_model
)

```

### control non-binoms with 1 epoch

```{r}
# --------------------------
# Load 1-epoch Control model data
# --------------------------
control_1epoch_model_data = read_csv(
  '../Data/FINETUNED_CONTROL_1EPOCH_MODEL_BINOMIAL_PREFERENCES.csv'
) %>%
  mutate(log_odds = preference) %>%
  separate(binom, c('Word1', 'and', 'Word2'), remove = FALSE, sep = ' ') %>%
  select(-and) %>%
  left_join(corpus) %>%
  mutate(
    y_vals = 0.02191943 + 0.23925834*Form + 0.24889543*Percept +
             0.41836997*Culture + 0.25967334*Power + 0.01867604*Intense +
             1.30365980*Icon + 0.08553552*Freq + 0.15241566*Len -
             0.19381657*Lapse + 0.36019221*`*BStress`,
    GenPref = plogis(y_vals) - 0.5,
    RelFreq = RelFreq - 0.5
  )

control_1epoch_model_data_novel =
  control_1epoch_model_data %>% filter(Attested == 0)

control_1epoch_model_data_attested =
  control_1epoch_model_data %>% filter(Attested == 1)

# --------------------------
# Item-level models
# --------------------------
control_1epoch_item_preds_novel = brm(
  log_odds ~ 1 + (1 | Alpha) + (1 | prompt),
  data   = control_1epoch_model_data_novel,
  prior  = prior_probs,
  iter   = 18000,
  warmup = 9000,
  chains = 4,
  cores  = 4,
  file   = '../Data/control_1epoch_item_preds_novel'
)

control_1epoch_item_preds_attested = brm(
  log_odds ~ 1 + (1 | Alpha) + (1 | prompt),
  data   = control_1epoch_model_data_attested,
  prior  = prior_probs,
  iter   = 20000,
  warmup = 10000,
  chains = 4,
  cores  = 4,
  file   = '../Data/control_1epoch_item_preds_attested'
)

# --------------------------
# Extract item predictions
# --------------------------
newdata_novel_control_1epoch = data.frame(
  Alpha  = unique(control_1epoch_model_data_novel$Alpha),
  prompt = NA
)

fitC_1epoch_novel = fitted(
  control_1epoch_item_preds_novel,
  newdata    = newdata_novel_control_1epoch,
  re_formula = ~(1 | Alpha),
  summary    = TRUE
)

item_df_control_1epoch_novel = data.frame(
  Alpha = newdata_novel_control_1epoch$Alpha,
  item_logodds_control_1epoch = fitC_1epoch_novel[, "Estimate"]
)

newdata_attested_control_1epoch = data.frame(
  Alpha  = unique(control_1epoch_model_data_attested$Alpha),
  prompt = NA
)

fitC_1epoch_attested = fitted(
  control_1epoch_item_preds_attested,
  newdata    = newdata_attested_control_1epoch,
  re_formula = ~(1 | Alpha),
  summary    = TRUE
)

item_df_control_1epoch_attested = data.frame(
  Alpha = newdata_attested_control_1epoch$Alpha,
  item_logodds_control_1epoch = fitC_1epoch_attested[, "Estimate"]
)

# --------------------------
# Join to human data
# --------------------------
human_data_novel_control_1epoch =
  all_human_data_novel %>%
  left_join(item_df_control_1epoch_novel, by = "Alpha")

human_data_attested_control_1epoch =
  all_human_data_attested %>%
  left_join(item_df_control_1epoch_attested, by = "Alpha")

# --------------------------
# Human choice models
# --------------------------
prior_probs_control_1epoch <- c(
  prior(normal(0, 1), class = "Intercept"),
  prior(normal(0, 1), class = "b", coef = "item_logodds_control_1epoch"),
  prior(student_t(3, 0, 1), class = "sd", group = "participant"),
  prior(student_t(3, 0, 1), class = "sd", group = "Alpha")
)

human_data_novel_control_1epoch_model = brm(
  resp_binary ~ item_logodds_control_1epoch + (1 | participant) + (1 | Alpha),
  data   = human_data_novel_control_1epoch,
  family = bernoulli(),
  prior  = prior_probs_control_1epoch,
  iter   = 6000,
  warmup = 3000,
  chains = 4,
  cores  = 4,
  file   = '../Data/human_data_novel_control_1epoch_model'
) %>% add_criterion("loo")

human_data_attested_control_1epoch_model = brm(
  resp_binary ~ item_logodds_control_1epoch + (1 | participant) + (1 | Alpha),
  data   = human_data_attested_control_1epoch,
  family = bernoulli(),
  prior  = prior_probs_control_1epoch,
  iter   = 6000,
  warmup = 3000,
  chains = 4,
  cores  = 4,
  file   = '../Data/human_data_attested_control_1epoch_model'
) %>% add_criterion("loo")

```

## Loo Results

```{r}


loo_results_novel = loo_compare(
  human_data_novel_baseline,
  human_data_novel_genpref_model,
  human_data_novel_genpref_old_model,
  human_data_novel_genpref_1epoch_model,
  human_data_novel_relfreq_model,
  human_data_novel_relfreq_1epoch_model,
  human_data_novel_control_model,
  human_data_novel_control_1epoch_model
)

loo_results_attested = loo_compare(
  human_data_attested_baseline,
  human_data_attested_genpref_model,
  human_data_attested_genpref_old_model,
  human_data_attested_genpref_1epoch_model,
  human_data_attested_relfreq_model,
  human_data_attested_relfreq_1epoch_model,
  human_data_attested_control_model,
  human_data_attested_control_1epoch_model
)



loo_results_novel
loo_results_attested
```

