---
title: "pythia analyses"
author: "Zachary Houghton"
date: "2025-12-22"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Pythia analyses

```{r}
library(tidyverse)
library(brms)

test_df  <- read_csv('../Data/attested_binoms_test.csv')
train_df <- read_csv('../Data/attested_binoms_train.csv')


# all_human_data = nonce_data
all_human_data = read_csv('../Human Data and Analyses/all_human_data.csv') %>%
  mutate(Attested = ifelse(
    OverallFreq == 0, 0, 1
  )) %>%
  select(participant, resp, Word1, Word2, Alpha, Nonalpha, OverallFreq, Word1_freq, Word2_freq, Form, Percept, Culture, Power, Intense, Icon, Freq, Len, Lapse, "*BStress", RelFreq, GenPref, Attested) %>%
  mutate(y_vals = 0.02191943 + 0.23925834*Form +  0.24889543*Percept +  0.41836997*Culture +   0.25967334*Power +  0.01867604*Intense +  1.30365980*Icon +   0.08553552*Freq +  0.15241566*Len - 0.19381657*Lapse +  0.36019221*`*BStress`) %>%
  mutate(GenPref = 1/(1+exp(-1*y_vals))) %>%
  mutate(GenPref = GenPref - 0.5)

all_human_data = all_human_data %>%
  mutate(resp_binary = case_when(
    resp == 'alpha' ~ 1,
    resp == 'nonalpha' ~ 0
  ))

all_human_data_novel    <- all_human_data %>% filter(Attested == 0)
all_human_data_attested <- all_human_data %>% filter(Attested == 1)



```

## Base analysis

### Statistical Predictors

```{r}
options(contrasts = c("contr.sum","contr.sum"))

corpus = read_csv('../Data/nonce_and_attested_binoms.csv')

pythia_baseline_model_data = read_csv('../Data/PYTHIA_BASE_MODEL_BINOMIAL_PREFERENCES.csv') %>%
  mutate(log_odds = preference) %>%
  separate(binom, c('Word1', 'and', 'Word2'), remove = F, sep = ' ') %>%
  select(-and) %>%
  #mutate(across(2:3, tolower)) %>%
  left_join(corpus) %>%
  mutate(checkpoint = 'main') %>%
  mutate(y_vals = 0.02191943 + 0.23925834*Form +  0.24889543*Percept +  0.41836997*Culture +   0.25967334*Power +  0.01867604*Intense +  1.30365980*Icon +   0.08553552*Freq +  0.15241566*Len - 0.19381657*Lapse +  0.36019221*`*BStress`) %>%
  mutate(GenPref = 1/(1+exp(-1*y_vals))) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5) %>%
  ungroup()


pythia_baseline_model_data_attested = pythia_baseline_model_data %>%
  ungroup() %>%
  filter(Attested == 1) %>%
  mutate(CenteredOverallFreq = as.numeric(scale(log(OverallFreq))))



pythia_baseline_model_data_novel = pythia_baseline_model_data %>%
  ungroup() %>%
  filter(Attested == 0)

pythia_baseline_model_data_attested$prompt = factor(pythia_baseline_model_data_attested$prompt)
pythia_baseline_model_data_novel$prompt = factor(pythia_baseline_model_data_novel$prompt)

pythia_baseline_model_data_novel = pythia_baseline_model_data_novel %>%
  rename(no_final_stress = "*BStress")

pythia_baseline_model_data_attested = pythia_baseline_model_data_attested %>%
  rename(no_final_stress = "*BStress")

pythia_model_attested_genpref = brm(log_odds ~ GenPref + RelFreq + CenteredOverallFreq + GenPref:CenteredOverallFreq + RelFreq:CenteredOverallFreq + (GenPref | prompt) + (1 | Alpha),
                       data = pythia_baseline_model_data_attested,
                       #prior = prior_probs,
                       iter = 10000,
                       warmup = 5000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       control = list(max_treedepth = 20),
                       file = '../Data/pythia_model_attested_genpref'
                      )


pythia_model_novel_genpref = brm(log_odds ~ GenPref + (GenPref | prompt) + (1 | Alpha),
                       data = pythia_baseline_model_data_novel,
                       #prior = prior_probs,
                       iter = 10000,
                       warmup = 5000,
                       chains = 4,
                       cores = 4,
                       #control = list(adapt_delta=0.99, max_treedepth = 15),
                       #control = list(max_treedepth = 20),
                       file = '../Data/pythia_model_novel_genpref'
                      )


 

fixef(pythia_model_attested_genpref)
fixef(pythia_model_novel_genpref)
```

### Human Analysis

#### Hand coded

```{r}
# ==================================================
# Pythia baseline: item preds -> join to humans -> human choice models
# (Drop-in rewrite of your hand-coded pipeline)
# ==================================================

library(tidyverse)
library(brms)

# --------------------------------------------------
# Load + prepare Pythia baseline data
# --------------------------------------------------
pythia_baseline_model_data <- read_csv(
  "../Data/PYTHIA_BASE_MODEL_BINOMIAL_PREFERENCES.csv"
) %>%
  mutate(log_odds = preference) %>%
  separate(binom, c("Word1", "and", "Word2"), remove = FALSE, sep = " ") %>%
  select(-and) %>%
  left_join(corpus, by = c("Word1", "Word2")) %>%   # safer than bare left_join()
  mutate(
    checkpoint = "main",
    y_vals =
      0.02191943 +
      0.23925834 * Form +
      0.24889543 * Percept +
      0.41836997 * Culture +
      0.25967334 * Power +
      0.01867604 * Intense +
      1.30365980 * Icon +
      0.08553552 * Freq +
      0.15241566 * Len -
      0.19381657 * Lapse +
      0.36019221 * `*BStress`,
    GenPref = plogis(y_vals) - 0.5,
    RelFreq = RelFreq - 0.5
  ) %>%
  ungroup()

# --------------------------------------------------
# Split into novel vs attested (match your previous logic)
# --------------------------------------------------
pythia_novel <-
  pythia_baseline_model_data %>%
  filter(Attested == 0)

pythia_attested <-
  pythia_baseline_model_data %>%
  filter(Alpha %in% test_df$Alpha)

# --------------------------------------------------
# Item-level models (Pythia baseline)
# --------------------------------------------------
# NOTE: I’m reusing your prior name `prior_probs` and the same model form.
# Adjust iter/warmup if you want them different from the hand-coded version.
pythia_item_preds_novel <- brm(
  log_odds ~ 1 + (1 | Alpha) + (1 | prompt),
  data   = pythia_novel,
  prior  = prior_probs,
  iter   = 18000,
  warmup = 9000,
  chains = 4,
  cores  = 4,
  file   = "../Data/pythia_item_preds_novel_main"
)

pythia_item_preds_attested <- brm(
  log_odds ~ 1 + (1 | Alpha) + (1 | prompt),
  data   = pythia_attested,
  prior  = prior_probs,
  iter   = 26000,
  warmup = 13000,
  chains = 4,
  cores  = 4,
  file   = "../Data/pythia_item_preds_attested_main"
)

# --------------------------------------------------
# Extract item predictions (renamed output column)
# --------------------------------------------------
extract_item_preds <- function(fit, alphas, out_col = "item_logodds_model") {
  newdata <- data.frame(
    Alpha  = unique(alphas),
    prompt = NA
  )

  fitted(
    fit,
    newdata    = newdata,
    re_formula = ~(1 | Alpha),
    summary    = TRUE
  )[,"Estimate"] %>%
    setNames(newdata$Alpha) %>%
    tibble::enframe(name = "Alpha", value = out_col)
}

item_df_pythia_attested <-
  extract_item_preds(
    pythia_item_preds_attested,
    pythia_attested$Alpha,
    out_col = "item_logodds_pythia"
  )

item_df_pythia_novel <-
  extract_item_preds(
    pythia_item_preds_novel,
    pythia_novel$Alpha,
    out_col = "item_logodds_pythia"
  )

# --------------------------------------------------
# Join to human data
# --------------------------------------------------
human_data_attested_pythia <-
  all_human_data_attested %>%
  semi_join(test_df, by = "Alpha") %>%
  left_join(item_df_pythia_attested, by = "Alpha")

human_data_novel_pythia <-
  all_human_data_novel %>%
  left_join(item_df_pythia_novel, by = "Alpha")

# Safety checks
stopifnot(!any(is.na(human_data_attested_pythia$item_logodds_pythia)))
stopifnot(!any(is.na(human_data_novel_pythia$item_logodds_pythia)))

# --------------------------------------------------
# Human choice models (Pythia baseline)
# --------------------------------------------------
prior_probs_pythia <- c(
  prior(normal(0, 1), class = "Intercept"),
  prior(normal(0, 1), class = "b", coef = "item_logodds_pythia"),
  prior(student_t(3, 0, 1), class = "sd", group = "participant"),
  prior(student_t(3, 0, 1), class = "sd", group = "Alpha")
)

human_data_attested_pythia_model <- brm(
  resp_binary ~ item_logodds_pythia + (1 | participant) + (1 | Alpha),
  data   = human_data_attested_pythia,
  family = bernoulli(),
  prior  = prior_probs_pythia,
  iter   = 6000,
  warmup = 3000,
  chains = 4,
  cores  = 4,
  file   = "../Data/human_data_attested_pythia_model_main"
) %>% add_criterion("loo")

human_data_novel_pythia_model <- brm(
  resp_binary ~ item_logodds_pythia + (1 | participant) + (1 | Alpha),
  data   = human_data_novel_pythia,
  family = bernoulli(),
  prior  = prior_probs_pythia,
  iter   = 6000,
  warmup = 3000,
  chains = 4,
  cores  = 4,
  file   = "../Data/human_data_novel_pythia_model_main"
) %>% add_criterion("loo")

```

#### GPT OSS 120B Coded Data

```{r}
# ==================================================
# PYTHIA baseline → item preds → humans → LOO
# (GenPref-OLD structure, Pythia data)
# ==================================================

library(tidyverse)
library(brms)

# --------------------------------------------------
# Split Pythia data into novel vs attested
# --------------------------------------------------
pythia_model_data_novel <-
  pythia_baseline_model_data %>%
  filter(Attested == 0)

pythia_model_data_attested <-
  pythia_baseline_model_data %>%
  filter(Attested == 1)

prior_probs <- c(
  prior(normal(0, 1), class = "Intercept"),
  prior(student_t(3, 0, 1), class = "sd", group = "Alpha"),
  prior(student_t(3, 0, 1), class = "sd", group = "prompt"),
  prior(student_t(3, 0, 1), class = "sigma")
)



# --------------------------------------------------
# Item-level models (log_odds ~ 1 + REs)
# --------------------------------------------------
pythia_item_preds_novel <- brm(
  log_odds ~ 1 + (1 | Alpha) + (1 | prompt),
  data   = pythia_model_data_novel,
  prior  = prior_probs,
  iter   = 18000,
  warmup = 9000,
  chains = 4,
  cores  = 4,
  file   = "../Data/pythia_item_preds_novel_main"
)

pythia_item_preds_attested <- brm(
  log_odds ~ 1 + (1 | Alpha) + (1 | prompt),
  data   = pythia_model_data_attested,
  prior  = prior_probs,
  iter   = 20000,
  warmup = 10000,
  chains = 4,
  cores  = 4,
  file   = "../Data/pythia_item_preds_attested_main"
)

# --------------------------------------------------
# Extract per-item predicted log-odds + CIs
# --------------------------------------------------
extract_item_preds_ci <- function(fit, alphas, prefix) {
  # Ensure we never trip factor-level mismatches
  alphas_chr <- unique(as.character(alphas))

  newdata <- data.frame(
    Alpha  = alphas_chr,
    prompt = NA_character_,
    stringsAsFactors = FALSE
  )

  fit_mat <- fitted(
    fit,
    newdata    = newdata,
    re_formula = ~(1 | Alpha),   # only item RE
    summary    = TRUE,
    allow_new_levels = TRUE      # critical if any level mismatch remains
  )

  tibble(
    Alpha = newdata$Alpha,
    !!paste0("item_logodds_", prefix) := fit_mat[, "Estimate"],
    !!paste0("item_lo_", prefix)      := fit_mat[, "Q2.5"],
    !!paste0("item_hi_", prefix)      := fit_mat[, "Q97.5"]
  )
}


item_df_pythia_novel <-
  extract_item_preds_ci(
    pythia_item_preds_novel,
    pythia_model_data_novel$Alpha,
    prefix = "pythia"
  )

item_df_pythia_attested <-
  extract_item_preds_ci(
    pythia_item_preds_attested,
    pythia_model_data_attested$Alpha,
    prefix = "pythia"
  )

# --------------------------------------------------
# Join to human data
# --------------------------------------------------
human_data_novel_pythia <-
  all_human_data_novel %>%
  semi_join(item_df_pythia_novel, by = "Alpha") %>%
  left_join(item_df_pythia_novel, by = "Alpha")

human_data_attested_pythia <-
  all_human_data_attested %>%
  semi_join(item_df_pythia_attested, by = "Alpha") %>%
  left_join(item_df_pythia_attested, by = "Alpha")

# Safety checks
stopifnot(!any(is.na(human_data_novel_pythia$item_logodds_pythia)))
stopifnot(!any(is.na(human_data_attested_pythia$item_logodds_pythia)))

# --------------------------------------------------
# Priors for human-choice model
# --------------------------------------------------
prior_probs_pythia <- c(
  prior(normal(0, 1), class = "Intercept"),
  prior(normal(0, 1), class = "b", coef = "item_logodds_pythia"),
  prior(student_t(3, 0, 1), class = "sd", group = "participant"),
  prior(student_t(3, 0, 1), class = "sd", group = "Alpha")
)

# --------------------------------------------------
# Human choice models (novel + attested)
# --------------------------------------------------
human_data_novel_pythia_model <- brm(
  resp_binary ~ item_logodds_pythia + (1 | participant) + (1 | Alpha),
  data      = human_data_novel_pythia,
  family    = bernoulli(link = "logit"),
  prior     = prior_probs_pythia,
  chains    = 4,
  cores     = 4,
  iter      = 6000,
  warmup    = 3000,
  save_pars = save_pars(all = TRUE),
  file      = "../Data/human_data_novel_pythia_model"
) %>% add_criterion("loo")

human_data_attested_pythia_model <- brm(
  resp_binary ~ item_logodds_pythia + (1 | participant) + (1 | Alpha),
  data      = human_data_attested_pythia,
  family    = bernoulli(link = "logit"),
  prior     = prior_probs_pythia,
  chains    = 4,
  cores     = 4,
  iter      = 6000,
  warmup    = 3000,
  save_pars = save_pars(all = TRUE),
  file      = "../Data/human_data_attested_pythia_model"
) %>% add_criterion("loo")



```

## GenPref Analysis

### Statistical Predictors
```{r}
options(contrasts = c("contr.sum","contr.sum"))

corpus = read_csv('../Data/nonce_and_attested_binoms.csv')

# --------------------------------------------------
# GENPREF-coded Pythia data (new input file)
# --------------------------------------------------
pythia_genpref_model_data = read_csv('../Data/PYTHIA_GENPREF_MODEL_BINOMIAL_PREFERENCES.csv') %>%
  mutate(log_odds = preference) %>%
  separate(binom, c('Word1', 'and', 'Word2'), remove = F, sep = ' ') %>%
  select(-and) %>%
  # mutate(across(2:3, tolower)) %>%
  left_join(corpus) %>%
  mutate(checkpoint = 'main') %>%
  mutate(y_vals = 0.02191943 + 0.23925834*Form +  0.24889543*Percept +  0.41836997*Culture +   0.25967334*Power +  0.01867604*Intense +  1.30365980*Icon +   0.08553552*Freq +  0.15241566*Len - 0.19381657*Lapse +  0.36019221*`*BStress`) %>%
  mutate(GenPref = 1/(1+exp(-1*y_vals))) %>%
  mutate(GenPref = GenPref - 0.5) %>%
  mutate(RelFreq = RelFreq - 0.5) %>%
  ungroup()

pythia_genpref_model_data_attested = pythia_genpref_model_data %>%
  ungroup() %>%
  filter(Attested == 1) %>%
  mutate(CenteredOverallFreq = as.numeric(scale(log(OverallFreq))))

pythia_genpref_model_data_novel = pythia_genpref_model_data %>%
  ungroup() %>%
  filter(Attested == 0)

pythia_genpref_model_data_attested$prompt = factor(pythia_genpref_model_data_attested$prompt)
pythia_genpref_model_data_novel$prompt    = factor(pythia_genpref_model_data_novel$prompt)

pythia_genpref_model_data_novel = pythia_genpref_model_data_novel %>%
  rename(no_final_stress = "*BStress")

pythia_genpref_model_data_attested = pythia_genpref_model_data_attested %>%
  rename(no_final_stress = "*BStress")

# --------------------------------------------------
# Models (same formulas; new object + file names)
# --------------------------------------------------
pythia_genpref_attested_genpref = brm(
  log_odds ~ GenPref + RelFreq + CenteredOverallFreq +
    GenPref:CenteredOverallFreq + RelFreq:CenteredOverallFreq +
    (GenPref | prompt) + (1 | Alpha),
  data   = pythia_genpref_model_data_attested,
  # prior  = prior_probs,
  iter   = 10000,
  warmup = 5000,
  chains = 4,
  cores  = 4,
  control = list(max_treedepth = 20),
  file   = '../Data/pythia_genpref_attested_genpref'
)

pythia_genpref_novel_genpref = brm(
  log_odds ~ GenPref + (GenPref | prompt) + (1 | Alpha),
  data   = pythia_genpref_model_data_novel,
  # prior  = prior_probs,
  iter   = 10000,
  warmup = 5000,
  chains = 4,
  cores  = 4,
  file   = '../Data/pythia_genpref_novel_genpref'
)

fixef(pythia_genpref_attested_genpref)
fixef(pythia_genpref_novel_genpref)

```

### Human Analysis

#### Hand coded

```{r}
# ==================================================
# Pythia GENPREF dataset: item preds -> join to humans -> human choice models
# (Drop-in rewrite of your hand-coded pipeline)
# ==================================================

library(tidyverse)
library(brms)

# --------------------------------------------------
# Load + prepare Pythia GENPREF data
# --------------------------------------------------
pythia_genpref_model_data <- read_csv(
  "../Data/PYTHIA_GENPREF_MODEL_BINOMIAL_PREFERENCES.csv"
) %>%
  mutate(log_odds = preference) %>%
  separate(binom, c("Word1", "and", "Word2"), remove = FALSE, sep = " ") %>%
  select(-and) %>%
  left_join(corpus, by = c("Word1", "Word2")) %>%   # safer than bare left_join()
  mutate(
    checkpoint = "main",
    y_vals =
      0.02191943 +
      0.23925834 * Form +
      0.24889543 * Percept +
      0.41836997 * Culture +
      0.25967334 * Power +
      0.01867604 * Intense +
      1.30365980 * Icon +
      0.08553552 * Freq +
      0.15241566 * Len -
      0.19381657 * Lapse +
      0.36019221 * `*BStress`,
    GenPref = plogis(y_vals) - 0.5,
    RelFreq = RelFreq - 0.5
  ) %>%
  ungroup()

# --------------------------------------------------
# Split into novel vs attested
# --------------------------------------------------
pythia_genpref_novel <-
  pythia_genpref_model_data %>%
  filter(Attested == 0)

pythia_genpref_attested <-
  pythia_genpref_model_data %>%
  filter(Alpha %in% test_df$Alpha)

# --------------------------------------------------
# Item-level models (Pythia GENPREF)
# --------------------------------------------------
pythia_genpref_item_preds_novel <- brm(
  log_odds ~ 1 + (1 | Alpha) + (1 | prompt),
  data   = pythia_genpref_novel,
  prior  = prior_probs,
  iter   = 18000,
  warmup = 9000,
  chains = 4,
  cores  = 4,
  file   = "../Data/pythia_genpref_item_preds_novel_main"
)

pythia_genpref_item_preds_attested <- brm(
  log_odds ~ 1 + (1 | Alpha) + (1 | prompt),
  data   = pythia_genpref_attested,
  prior  = prior_probs,
  iter   = 26000,
  warmup = 13000,
  chains = 4,
  cores  = 4,
  file   = "../Data/pythia_genpref_item_preds_attested_main"
)

# --------------------------------------------------
# Extract item predictions
# --------------------------------------------------
extract_item_preds <- function(fit, alphas, out_col = "item_logodds_model") {
  newdata <- data.frame(
    Alpha  = unique(alphas),
    prompt = NA
  )

  fitted(
    fit,
    newdata    = newdata,
    re_formula = ~(1 | Alpha),
    summary    = TRUE
  )[,"Estimate"] %>%
    setNames(newdata$Alpha) %>%
    tibble::enframe(name = "Alpha", value = out_col)
}

item_df_pythia_genpref_attested <-
  extract_item_preds(
    pythia_genpref_item_preds_attested,
    pythia_genpref_attested$Alpha,
    out_col = "item_logodds_pythia_genpref"
  )

item_df_pythia_genpref_novel <-
  extract_item_preds(
    pythia_genpref_item_preds_novel,
    pythia_genpref_novel$Alpha,
    out_col = "item_logodds_pythia_genpref"
  )

extract_item_preds_ci <- function(fit, alphas, prefix) {
  # Ensure we never trip factor-level mismatches
  alphas_chr <- unique(as.character(alphas))

  newdata <- data.frame(
    Alpha  = alphas_chr,
    prompt = NA_character_,
    stringsAsFactors = FALSE
  )

  fit_mat <- fitted(
    fit,
    newdata    = newdata,
    re_formula = ~(1 | Alpha),   # only item RE
    summary    = TRUE,
    allow_new_levels = TRUE      # critical if any level mismatch remains
  )

  tibble(
    Alpha = newdata$Alpha,
    !!paste0("item_logodds_", prefix) := fit_mat[, "Estimate"],
    !!paste0("item_lo_", prefix)      := fit_mat[, "Q2.5"],
    !!paste0("item_hi_", prefix)      := fit_mat[, "Q97.5"]
  )
}

# --------------------------------------------------
# Join to human data
# --------------------------------------------------
human_data_attested_pythia_genpref <-
  all_human_data_attested %>%
  semi_join(test_df, by = "Alpha") %>%
  left_join(item_df_pythia_genpref_attested, by = "Alpha")

human_data_novel_pythia_genpref <-
  all_human_data_novel %>%
  left_join(item_df_pythia_genpref_novel, by = "Alpha")

# Safety checks
stopifnot(!any(is.na(human_data_attested_pythia_genpref$item_logodds_pythia_genpref)))
stopifnot(!any(is.na(human_data_novel_pythia_genpref$item_logodds_pythia_genpref)))

# --------------------------------------------------
# Human choice models (Pythia GENPREF)
# --------------------------------------------------
prior_probs_pythia_genpref <- c(
  prior(normal(0, 1), class = "Intercept"),
  prior(normal(0, 1), class = "b", coef = "item_logodds_pythia_genpref"),
  prior(student_t(3, 0, 1), class = "sd", group = "participant"),
  prior(student_t(3, 0, 1), class = "sd", group = "Alpha")
)

human_data_attested_pythia_genpref_model <- brm(
  resp_binary ~ item_logodds_pythia_genpref + (1 | participant) + (1 | Alpha),
  data   = human_data_attested_pythia_genpref,
  family = bernoulli(),
  prior  = prior_probs_pythia_genpref,
  iter   = 6000,
  warmup = 3000,
  chains = 4,
  cores  = 4,
  file   = "../Data/human_data_attested_pythia_genpref_model_main"
) %>% add_criterion("loo")

human_data_novel_pythia_genpref_model <- brm(
  resp_binary ~ item_logodds_pythia_genpref + (1 | participant) + (1 | Alpha),
  data   = human_data_novel_pythia_genpref,
  family = bernoulli(),
  prior  = prior_probs_pythia_genpref,
  iter   = 6000,
  warmup = 3000,
  chains = 4,
  cores  = 4,
  file   = "../Data/human_data_novel_pythia_genpref_model_main"
) %>% add_criterion("loo")

```

#### GPT OSS 120B Coded Data
```{r}
# ==================================================
# PYTHIA GENPREF → item preds → humans → LOO
# (GenPref-OLD structure, Pythia GENPREF data)
# ==================================================

library(tidyverse)
library(brms)

# --------------------------------------------------
# Load + prepare Pythia GENPREF data
# --------------------------------------------------
pythia_genpref_model_data <- read_csv(
  "../Data/PYTHIA_GENPREF_MODEL_BINOMIAL_PREFERENCES.csv"
) %>%
  mutate(log_odds = preference) %>%
  separate(binom, c("Word1", "and", "Word2"), remove = FALSE, sep = " ") %>%
  select(-and) %>%
  left_join(corpus, by = c("Word1", "Word2")) %>%
  mutate(
    checkpoint = "main",
    y_vals =
      0.02191943 +
      0.23925834 * Form +
      0.24889543 * Percept +
      0.41836997 * Culture +
      0.25967334 * Power +
      0.01867604 * Intense +
      1.30365980 * Icon +
      0.08553552 * Freq +
      0.15241566 * Len -
      0.19381657 * Lapse +
      0.36019221 * `*BStress`,
    GenPref = plogis(y_vals) - 0.5,
    RelFreq = RelFreq - 0.5
  ) %>%
  ungroup()

# --------------------------------------------------
# Split Pythia GENPREF data into novel vs attested
# --------------------------------------------------
pythia_genpref_novel <-
  pythia_genpref_model_data %>%
  filter(Attested == 0)

pythia_genpref_attested <-
  pythia_genpref_model_data %>%
  filter(Attested == 1)

# --------------------------------------------------
# Priors (same as baseline)
# --------------------------------------------------
prior_probs <- c(
  prior(normal(0, 1), class = "Intercept"),
  prior(student_t(3, 0, 1), class = "sd", group = "Alpha"),
  prior(student_t(3, 0, 1), class = "sd", group = "prompt"),
  prior(student_t(3, 0, 1), class = "sigma")
)

# --------------------------------------------------
# Item-level models (GENPREF)
# --------------------------------------------------
pythia_genpref_item_preds_novel <- brm(
  log_odds ~ 1 + (1 | Alpha) + (1 | prompt),
  data   = pythia_genpref_novel,
  prior  = prior_probs,
  iter   = 18000,
  warmup = 9000,
  chains = 4,
  cores  = 4,
  file   = "../Data/pythia_genpref_item_preds_novel_main"
)

pythia_genpref_item_preds_attested <- brm(
  log_odds ~ 1 + (1 | Alpha) + (1 | prompt),
  data   = pythia_genpref_attested,
  prior  = prior_probs,
  iter   = 20000,
  warmup = 10000,
  chains = 4,
  cores  = 4,
  file   = "../Data/pythia_genpref_item_preds_attested_main"
)

# --------------------------------------------------
# Extract per-item predicted log-odds + CIs
# --------------------------------------------------

extract_item_preds_ci <- function(fit, alphas, prefix) {
  # Ensure we never trip factor-level mismatches
  alphas_chr <- unique(as.character(alphas))

  newdata <- data.frame(
    Alpha  = alphas_chr,
    prompt = NA_character_,
    stringsAsFactors = FALSE
  )

  fit_mat <- fitted(
    fit,
    newdata    = newdata,
    re_formula = ~(1 | Alpha),   # only item RE
    summary    = TRUE,
    allow_new_levels = TRUE      # critical if any level mismatch remains
  )

  tibble(
    Alpha = newdata$Alpha,
    !!paste0("item_logodds_", prefix) := fit_mat[, "Estimate"],
    !!paste0("item_lo_", prefix)      := fit_mat[, "Q2.5"],
    !!paste0("item_hi_", prefix)      := fit_mat[, "Q97.5"]
  )
}

item_df_pythia_genpref_novel <-
  extract_item_preds_ci(
    pythia_genpref_item_preds_novel,
    pythia_genpref_novel$Alpha,
    prefix = "pythia_genpref"
  )

item_df_pythia_genpref_attested <-
  extract_item_preds_ci(
    pythia_genpref_item_preds_attested,
    pythia_genpref_attested$Alpha,
    prefix = "pythia_genpref"
  )

# --------------------------------------------------
# Join to human data
# --------------------------------------------------
human_data_novel_pythia_genpref <-
  all_human_data_novel %>%
  semi_join(item_df_pythia_genpref_novel, by = "Alpha") %>%
  left_join(item_df_pythia_genpref_novel, by = "Alpha")

human_data_attested_pythia_genpref <-
  all_human_data_attested %>%
  semi_join(item_df_pythia_genpref_attested, by = "Alpha") %>%
  left_join(item_df_pythia_genpref_attested, by = "Alpha")

# Safety checks
stopifnot(!any(is.na(human_data_novel_pythia_genpref$item_logodds_pythia_genpref)))
stopifnot(!any(is.na(human_data_attested_pythia_genpref$item_logodds_pythia_genpref)))

# --------------------------------------------------
# Priors for human-choice model
# --------------------------------------------------
prior_probs_pythia_genpref <- c(
  prior(normal(0, 1), class = "Intercept"),
  prior(normal(0, 1), class = "b", coef = "item_logodds_pythia_genpref"),
  prior(student_t(3, 0, 1), class = "sd", group = "participant"),
  prior(student_t(3, 0, 1), class = "sd", group = "Alpha")
)

# --------------------------------------------------
# Human choice models (GENPREF: novel + attested)
# --------------------------------------------------
human_data_novel_pythia_genpref_model <- brm(
  resp_binary ~ item_logodds_pythia_genpref + (1 | participant) + (1 | Alpha),
  data      = human_data_novel_pythia_genpref,
  family    = bernoulli(link = "logit"),
  prior     = prior_probs_pythia_genpref,
  chains    = 4,
  cores     = 4,
  iter      = 6000,
  warmup    = 3000,
  save_pars = save_pars(all = TRUE),
  file      = "../Data/human_data_novel_pythia_genpref_model"
) %>% add_criterion("loo")

human_data_attested_pythia_genpref_model <- brm(
  resp_binary ~ item_logodds_pythia_genpref + (1 | participant) + (1 | Alpha),
  data      = human_data_attested_pythia_genpref,
  family    = bernoulli(link = "logit"),
  prior     = prior_probs_pythia_genpref,
  chains    = 4,
  cores     = 4,
  iter      = 6000,
  warmup    = 3000,
  save_pars = save_pars(all = TRUE),
  file      = "../Data/human_data_attested_pythia_genpref_model"
) %>% add_criterion("loo")

```


